{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "EntLink_RoBerta.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "ghKTiGzgvicT",
        "txCNhgh3IcP-",
        "7pQub9q-p-w4",
        "K80KuBLOGmhx",
        "ofrsuUEuGmiG"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "7ece8f8e65c0482a80dca9f90652131a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_75155db6e8bd495685501d583b3d6123",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_92de7e9a864343caab4edf70ab15f532",
              "IPY_MODEL_29f3c9cfe2494271943ce84e5ab13a0e",
              "IPY_MODEL_a7f24eb108cf4015997e0aa611cb8b84"
            ]
          }
        },
        "75155db6e8bd495685501d583b3d6123": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "92de7e9a864343caab4edf70ab15f532": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_b8aac3ea9dbd4fd9894a1c38073d3208",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "Downloading: 100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_1d9ff92a176a4c11a36beff54ff4c810"
          }
        },
        "29f3c9cfe2494271943ce84e5ab13a0e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_adf60efcad564c8bba4af6113dac5d22",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 512,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 512,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_0d594bc6ffe14e34a293965bc568c53f"
          }
        },
        "a7f24eb108cf4015997e0aa611cb8b84": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_f81e80c333904064b060373a45339416",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 512/512 [00:00&lt;00:00, 11.7kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_1e7665faf2ec4344825e9b624632ea04"
          }
        },
        "b8aac3ea9dbd4fd9894a1c38073d3208": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "1d9ff92a176a4c11a36beff54ff4c810": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "adf60efcad564c8bba4af6113dac5d22": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "0d594bc6ffe14e34a293965bc568c53f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "f81e80c333904064b060373a45339416": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "1e7665faf2ec4344825e9b624632ea04": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mavillot/FUNSD-Entity-Linking/blob/main/RoBerta.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eoWYsfAj5KrP"
      },
      "source": [
        "# Modelo de lenguaje"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jv2NEZ_XAlQ-"
      },
      "source": [
        "## Data preparation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9jNuJScWvS58"
      },
      "source": [
        "### Dataset:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5sZiqEN1tArs"
      },
      "source": [
        "%%capture\n",
        "!wget https://guillaumejaume.github.io/FUNSD/dataset.zip -O dataset.zip\n",
        "!unzip dataset.zip"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K80KuBLOGmhx"
      },
      "source": [
        "### Extracting candidates "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yYcsCwBK0F6X"
      },
      "source": [
        "import json\n",
        "from pathlib import Path\n",
        "import cv2\n",
        "import numpy as np"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lgCFh_RnGmiD"
      },
      "source": [
        "def candidates(path):\n",
        "  anot=json.loads(open(path).read())\n",
        "  img=Path(path).stem+'.png'\n",
        "  path_image=Path(path).parent.parent/'images'/img\n",
        "  h,w,_=cv2.imread(str(path_image)).shape\n",
        "  question, answer=[],[]\n",
        "  text={}\n",
        "  for block in anot['form']:\n",
        "    if block['label']=='question':\n",
        "      question.append([block['id'],block['box']])\n",
        "      text[block['id']]=block['text']\n",
        "    if block['label']=='answer':\n",
        "      answer.append([block['id'],block['box']])\n",
        "      text[block['id']]=block['text']\n",
        "  # We have built 2 list with answers and questions' info \n",
        "  #For each answer we look for its question\n",
        "  dic={}\n",
        "  for a in answer:\n",
        "    bbox=a[1]\n",
        "    candidates=[]\n",
        "    candidates_more=[]\n",
        "    x_a=int(bbox[0])\n",
        "    x1_a=int(bbox[2])\n",
        "    y_a=int(bbox[1])\n",
        "    y1_a=int(bbox[3])\n",
        "    pto_a=[(x_a+x1_a)/2,(y_a+y1_a)/2]\n",
        "    for q in question:\n",
        "      bbox=q[1]\n",
        "      x_q=int(bbox[0])\n",
        "      x1_q=int(bbox[2])\n",
        "      y_q=int(bbox[1])\n",
        "      y1_q=int(bbox[3])\n",
        "      pto_q=[(x_q+x1_q)/2,(y_q+y1_q)/2]\n",
        "      if x_q<x1_a+0.05*w and y1_q>y_a-0.1*h and y_q<y1_a+0.01*h:\n",
        "        dist=np.sqrt((x_a-x1_q)**2+(pto_a[1]-pto_q[1])**2)\n",
        "        candidates.append([q[0],dist])\n",
        "      if x_q<x1_a +0.05*w and y1_q>y_a-0.6*h and y_q<y1_a+0.03*h:\n",
        "        dist=np.sqrt((x_a-x1_q)**2+(pto_a[1]-pto_q[1])**2)\n",
        "        candidates_more.append([q[0],dist])\n",
        "    if candidates!=[]:\n",
        "      dic[a[0]]=candidates\n",
        "    else:\n",
        "      dic[a[0]]=candidates_more\n",
        "  return dic,text"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P50Ykdn3GmiF",
        "outputId": "c46e76ba-f168-4733-8459-e96c27a4592f"
      },
      "source": [
        "candidates('dataset/training_data/annotations/0000971160.json')"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "({4: [[1, 286.05287972680856],\n",
              "   [3, 41.593268686170845],\n",
              "   [10, 309.0457085934053],\n",
              "   [13, 20.006249023742555],\n",
              "   [15, 293.0959740426334]],\n",
              "  11: [[3, 303.0264014900352], [10, 11.10180165558726]],\n",
              "  12: [[3, 25.243811122728676], [10, 339.1194479825656]],\n",
              "  14: [[1, 11.10180165558726],\n",
              "   [10, 50.835519078691426],\n",
              "   [15, 18.33712082089225]],\n",
              "  16: [[1, 82.76472678623425],\n",
              "   [2, 39.96248240537617],\n",
              "   [3, 349.7802881810237],\n",
              "   [10, 116.84177335182824],\n",
              "   [13, 311.4498354470588],\n",
              "   [15, 78.18567643756751]],\n",
              "  18: [[17, 26.419689627245813]],\n",
              "  21: [[5, 15.402921800749363],\n",
              "   [6, 254.32656172724074],\n",
              "   [7, 333.7813655673426],\n",
              "   [20, 21.587033144922902]],\n",
              "  22: [[5, 118.71394189394942], [20, 112.58885380000989]]},\n",
              " {1: ':',\n",
              "  2: 'Suggestion:',\n",
              "  3: 'Date:',\n",
              "  4: 'Licensee',\n",
              "  5: '',\n",
              "  6: 'Yes',\n",
              "  7: 'No',\n",
              "  10: 'Name / Phone Ext. :',\n",
              "  11: 'M. Hamann P. Harper, P. Martinez',\n",
              "  12: '9/ 3/ 92',\n",
              "  13: 'R&D Group:',\n",
              "  14: 'J. S. Wigand',\n",
              "  15: 'Supervisor / Manager',\n",
              "  16: 'Discontinue coal retention analyses on licensee submitted product samples (Note : Coal Retention testing is not performed by most licensees. Other B&W physical measurements as ends stability and inspection for soft spots in ciparettes are thought to be sufficient measures to assure cigarette physical integrity. The proposed action will increase laboratory productivity . )',\n",
              "  17: 'Suggested Solutions (s) :',\n",
              "  18: 'Delete coal retention from the list of standard analyses performed on licensee submitted product samples. Special requests for coal retention testing could still be submitted on an exception basis.',\n",
              "  20: 'Manager Comments:',\n",
              "  21: 'Manager, please contact suggester and forward',\n",
              "  22: 'comments to the Quality Council.'})"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IT5CSGNWK0y8"
      },
      "source": [
        "We rank the candidates according to the distance"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wlj81pRnPdEG"
      },
      "source": [
        "from operator import itemgetter"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yB0B99CmK0cS"
      },
      "source": [
        "def rank(path):\n",
        "  cand,text=candidates(path)\n",
        "  for c in cand:\n",
        "    aux=cand[c]\n",
        "    cand[c]=[l[0] for l in sorted(aux, key=itemgetter(1))]\n",
        "  return cand,text"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xa2BZOTaMfpE",
        "outputId": "0e750033-09b8-48a5-8b8a-1cee00bc3531"
      },
      "source": [
        "rank('dataset/training_data/annotations/0000971160.json')"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "({4: [13, 3, 1, 15, 10],\n",
              "  11: [10, 3],\n",
              "  12: [3, 10],\n",
              "  14: [1, 15, 10],\n",
              "  16: [2, 15, 1, 10, 13, 3],\n",
              "  18: [17],\n",
              "  21: [5, 20, 6, 7],\n",
              "  22: [20, 5]},\n",
              " {1: ':',\n",
              "  2: 'Suggestion:',\n",
              "  3: 'Date:',\n",
              "  4: 'Licensee',\n",
              "  5: '',\n",
              "  6: 'Yes',\n",
              "  7: 'No',\n",
              "  10: 'Name / Phone Ext. :',\n",
              "  11: 'M. Hamann P. Harper, P. Martinez',\n",
              "  12: '9/ 3/ 92',\n",
              "  13: 'R&D Group:',\n",
              "  14: 'J. S. Wigand',\n",
              "  15: 'Supervisor / Manager',\n",
              "  16: 'Discontinue coal retention analyses on licensee submitted product samples (Note : Coal Retention testing is not performed by most licensees. Other B&W physical measurements as ends stability and inspection for soft spots in ciparettes are thought to be sufficient measures to assure cigarette physical integrity. The proposed action will increase laboratory productivity . )',\n",
              "  17: 'Suggested Solutions (s) :',\n",
              "  18: 'Delete coal retention from the list of standard analyses performed on licensee submitted product samples. Special requests for coal retention testing could still be submitted on an exception basis.',\n",
              "  20: 'Manager Comments:',\n",
              "  21: 'Manager, please contact suggester and forward',\n",
              "  22: 'comments to the Quality Council.'})"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ofrsuUEuGmiG"
      },
      "source": [
        "We construct now a function that given a path it returns for each answer the candidates, the labels and the text of the questions and answers"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vqNb6yjyGmiG"
      },
      "source": [
        "def candidatesANDlabels(path):\n",
        "  anot=json.loads(open(path).read())\n",
        "  cand,text=rank(path)\n",
        "  dic_label={}\n",
        "  for block in anot['form']:\n",
        "    if block['label']=='answer':\n",
        "      id=block['id']\n",
        "      id_question=[]\n",
        "      for link in block['linking']:\n",
        "        if link[0]==id:\n",
        "          id_question.append(link[1])\n",
        "        else: id_question.append(link[0])\n",
        "      lista=cand[id]\n",
        "      labels=[lista[i] in id_question for i in range(0,len(lista))]\n",
        "      dic_label[id]=labels\n",
        "  return cand,dic_label,text     "
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gBMh6IjYGmiH",
        "outputId": "7c287462-a647-470f-fa3e-293c39f9216a"
      },
      "source": [
        "candidatesANDlabels('dataset/training_data/annotations/0000971160.json')"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "({4: [13, 3, 1, 15, 10],\n",
              "  11: [10, 3],\n",
              "  12: [3, 10],\n",
              "  14: [1, 15, 10],\n",
              "  16: [2, 15, 1, 10, 13, 3],\n",
              "  18: [17],\n",
              "  21: [5, 20, 6, 7],\n",
              "  22: [20, 5]},\n",
              " {4: [True, False, False, False, False],\n",
              "  11: [True, False],\n",
              "  12: [True, False],\n",
              "  14: [False, True, False],\n",
              "  16: [True, False, False, False, False, False],\n",
              "  18: [True],\n",
              "  21: [False, True, False, False],\n",
              "  22: [True, False]},\n",
              " {1: ':',\n",
              "  2: 'Suggestion:',\n",
              "  3: 'Date:',\n",
              "  4: 'Licensee',\n",
              "  5: '',\n",
              "  6: 'Yes',\n",
              "  7: 'No',\n",
              "  10: 'Name / Phone Ext. :',\n",
              "  11: 'M. Hamann P. Harper, P. Martinez',\n",
              "  12: '9/ 3/ 92',\n",
              "  13: 'R&D Group:',\n",
              "  14: 'J. S. Wigand',\n",
              "  15: 'Supervisor / Manager',\n",
              "  16: 'Discontinue coal retention analyses on licensee submitted product samples (Note : Coal Retention testing is not performed by most licensees. Other B&W physical measurements as ends stability and inspection for soft spots in ciparettes are thought to be sufficient measures to assure cigarette physical integrity. The proposed action will increase laboratory productivity . )',\n",
              "  17: 'Suggested Solutions (s) :',\n",
              "  18: 'Delete coal retention from the list of standard analyses performed on licensee submitted product samples. Special requests for coal retention testing could still be submitted on an exception basis.',\n",
              "  20: 'Manager Comments:',\n",
              "  21: 'Manager, please contact suggester and forward',\n",
              "  22: 'comments to the Quality Council.'})"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7pQub9q-p-w4"
      },
      "source": [
        "### Dataset Class\n",
        "\n",
        "We create this class in order to obtain the dataset we will use for training the BERT model. \n",
        "For each form we extract all the answers and its candidates for question. For each candidate we concatenate its text with the answer text. If the link between those 2 entities exists the label will be: 1 and if it doesn't exist it will be 0."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eoHvWXOa9sOC"
      },
      "source": [
        "import os\n",
        "class Dataset():\n",
        "    def __init__(self, path_annotation):\n",
        "        self.path_annotation= path_annotation\n",
        "\n",
        "    def __iter__(self):\n",
        "      with os.scandir(self.path_annotation) as files:\n",
        "        for file in files:\n",
        "          yield file.name\n",
        "          \n",
        "    def __len__(self):\n",
        "      i=0\n",
        "      for file in self:\n",
        "        i+=1\n",
        "      return i\n",
        "\n",
        "    def textList(self, o):\n",
        "      path=self.path_annotation+'/'+o\n",
        "      cand,label,text=candidatesANDlabels(path)\n",
        "      question_answer,et=[],[]\n",
        "      dic={True:1,False:0}\n",
        "      for c in cand:\n",
        "        question_answer=question_answer+[text[x]+' '+text[c] for x in cand[c]]\n",
        "        et=et+[dic[z] for z in label[c]]\n",
        "      return question_answer,et\n",
        "    \n",
        "    def preparation(self):\n",
        "      text=[]\n",
        "      label=[]\n",
        "      for file in self:\n",
        "        txt,lbl=self.textList(file)\n",
        "        text=text+txt\n",
        "        label=label+lbl\n",
        "      return (text,label)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gZR_FPAk-Jv_"
      },
      "source": [
        "dataset_train=Dataset('dataset/training_data/annotations')\n",
        "dataset_test=Dataset('dataset/testing_data/annotations')"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D411kM4R-JwA"
      },
      "source": [
        "text_train, labels_train=dataset_train.preparation()\n",
        "text_test, labels_test=dataset_test.preparation()"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dauKcE4PyLvW"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "train_texts, val_texts, train_labels, val_labels = train_test_split(text_train, labels_train, test_size=.2)"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I5rUCbt9R90S"
      },
      "source": [
        "**We check if all the answers have at least one question in their candidates:**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6FZrZMpBPxfJ",
        "outputId": "c9c2d30e-f702-4bf7-f328-7ea03789f9c6"
      },
      "source": [
        "path='/content/dataset/training_data/annotations/'\n",
        "i=0\n",
        "for f in dataset_train:\n",
        "  f=path+f\n",
        "  cand,_,_=candidatesANDlabels(f)\n",
        "  for c in cand:\n",
        "    if cand[c]==[]:\n",
        "      i+=1\n",
        "print(i)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9De31K65BFLt"
      },
      "source": [
        "There's no answer without candidates"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ApCMyoP2SQuC"
      },
      "source": [
        "**We check if all the correct questions are in the candidate list of the answer:**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qhMaLeVXN9Li",
        "outputId": "09021392-ada5-4dfb-f39b-d5e13ac5089c"
      },
      "source": [
        "path='/content/dataset/training_data/annotations/'\n",
        "i,j=0,0\n",
        "for f in dataset_train:\n",
        "  f=path+f\n",
        "  cand,lbl,text=candidatesANDlabels(f)\n",
        "  for k in lbl:\n",
        "    j+=1\n",
        "    if not(True in lbl[k]):\n",
        "      i+=1\n",
        "print(i,j)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "47 2802\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VTvP1DyGTlu-",
        "outputId": "db763e32-de95-4a53-8181-6151fdc6e633"
      },
      "source": [
        "47*100/2802"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1.6773733047822983"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tWDWXVLZBPHq"
      },
      "source": [
        "Ther're 47 of the 2802 answers (1.68%) who haven't got their correct question in the candidates"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O0lkdWyJqCKm"
      },
      "source": [
        "### FUNSDataset Class\n",
        "\n",
        "This class helps us to pass the dataset in a format that the model understands."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5c_k-d9bCKDh"
      },
      "source": [
        "import torch\n",
        "class FUNDSDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, encodings, labels):\n",
        "        self.encodings = encodings\n",
        "        self.labels = torch.tensor(labels)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
        "        item['labels'] = torch.tensor(self.labels[idx])\n",
        "        return item\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.labels)"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FRhb9ps7qNwI"
      },
      "source": [
        "## Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "28HYwtoMvRkJ"
      },
      "source": [
        "%%capture\n",
        "pip install transformers"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "32IDKwgZqLkI"
      },
      "source": [
        "#### Metrics\n",
        "\n",
        "These are the metrics we will be using for training."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x6HkktDs9R0g"
      },
      "source": [
        "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
        "\n",
        "def compute_metrics(pred):\n",
        "    labels = pred.label_ids\n",
        "    preds = pred.predictions.argmax(-1)\n",
        "    precision, recall, f1, _ = precision_recall_fscore_support(labels, preds, average='binary')\n",
        "    acc = accuracy_score(labels, preds)\n",
        "    return {\n",
        "        'accuracy': acc,\n",
        "        'f1': f1,\n",
        "        'precision': precision,\n",
        "        'recall': recall\n",
        "    }"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QBnu_PMSWoQu"
      },
      "source": [
        "##### mAP"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P2eHhDsIWoQu"
      },
      "source": [
        "import numpy as np\n",
        "from sklearn.metrics import average_precision_score\n",
        "\n",
        "def mAP_x(scores, labels):\n",
        "  m=average_precision_score(labels, scores)\n",
        "  if np.isnan(m):\n",
        "    return 0\n",
        "  else:\n",
        "    return m"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U4MJSWZKBWOt"
      },
      "source": [
        "def mAP(dataset,coef_FINAL,labels):\n",
        "  i=0\n",
        "  map=[]\n",
        "  for f in dataset:\n",
        "    cand,txt=rank(dataset.path_annotation+ '/' +f)\n",
        "    n=len(cand)\n",
        "    if n>0:\n",
        "      for c in cand:\n",
        "        j=i+len(cand[c])\n",
        "        map.append(mAP_x(coef_FINAL[i:j],labels[i:j]))\n",
        "        i=j\n",
        "  return sum(map)/len(map)"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jxg7wjrTWoQu"
      },
      "source": [
        "##### mRank"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kE7F4d9OWoQv"
      },
      "source": [
        "import numpy as np\n",
        "def mRank_x(predictions, labels,coef):\n",
        "  if predictions==labels:\n",
        "    return 0\n",
        "  else:\n",
        "    if 1 in labels:\n",
        "      k=labels.index(1)\n",
        "      return sum([c>coef[k] for c in coef])\n",
        "    else:\n",
        "      return len(predictions)"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m0kSTG4_WoQv"
      },
      "source": [
        "def mRank(dataset,prediction,labels,coef):\n",
        "  mrank=[]\n",
        "  i=0\n",
        "  for f in dataset:\n",
        "    cand,txt=rank(dataset.path_annotation+ '/' +f)\n",
        "    n=len(cand)\n",
        "    if n>0: #comprobamos que el documento tenga algun par clave-valor\n",
        "      for c in cand:\n",
        "        j=i+len(cand[c])\n",
        "        if j!=i:\n",
        "          mrank.append(mRank_x(prediction[i:j],labels[i:j],coef[i:j]))\n",
        "          i=j\n",
        "  return sum(mrank)/len(mrank)"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KELzPZz34PpO"
      },
      "source": [
        "#### Tokenizer and the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "referenced_widgets": [
            "7ece8f8e65c0482a80dca9f90652131a",
            "75155db6e8bd495685501d583b3d6123",
            "92de7e9a864343caab4edf70ab15f532",
            "29f3c9cfe2494271943ce84e5ab13a0e",
            "a7f24eb108cf4015997e0aa611cb8b84",
            "b8aac3ea9dbd4fd9894a1c38073d3208",
            "1d9ff92a176a4c11a36beff54ff4c810",
            "adf60efcad564c8bba4af6113dac5d22",
            "0d594bc6ffe14e34a293965bc568c53f",
            "f81e80c333904064b060373a45339416",
            "1e7665faf2ec4344825e9b624632ea04",
            "3c831493720f43b1b090d48264caf38b",
            "63c1cb4411b14df6b269542e0ff90261",
            "7090187945d14799a2454383c41336dc"
          ]
        },
        "id": "MiLQH8EYrIDM",
        "outputId": "af52424b-b9eb-488f-b403-5f11846ce11c"
      },
      "source": [
        "from transformers import BertForSequenceClassification,AutoTokenizer,Trainer, TrainingArguments\n",
        "tokenizer = AutoTokenizer.from_pretrained('xlm-roberta-base')\n",
        "model = BertForSequenceClassification.from_pretrained('xlm-roberta-base', num_labels=2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "7ece8f8e65c0482a80dca9f90652131a",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/512 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "3c831493720f43b1b090d48264caf38b",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/4.83M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "63c1cb4411b14df6b269542e0ff90261",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/8.68M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are using a model of type xlm-roberta to instantiate a model of type bert. This is not supported for all configurations of models and can yield errors.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "7090187945d14799a2454383c41336dc",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/1.04G [00:00<?, ?B/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing BertForSequenceClassification: ['roberta.encoder.layer.1.intermediate.dense.weight', 'roberta.encoder.layer.2.intermediate.dense.bias', 'roberta.encoder.layer.8.attention.self.query.weight', 'roberta.encoder.layer.0.intermediate.dense.weight', 'roberta.pooler.dense.bias', 'roberta.encoder.layer.1.attention.self.key.bias', 'roberta.encoder.layer.5.intermediate.dense.bias', 'lm_head.dense.bias', 'roberta.encoder.layer.1.attention.self.key.weight', 'roberta.encoder.layer.2.output.LayerNorm.bias', 'roberta.encoder.layer.1.attention.output.LayerNorm.weight', 'roberta.encoder.layer.4.output.LayerNorm.weight', 'roberta.encoder.layer.2.output.LayerNorm.weight', 'roberta.encoder.layer.9.attention.self.query.bias', 'roberta.encoder.layer.10.output.dense.weight', 'roberta.encoder.layer.7.output.LayerNorm.bias', 'roberta.encoder.layer.6.intermediate.dense.weight', 'roberta.encoder.layer.0.attention.output.dense.bias', 'roberta.encoder.layer.3.attention.self.key.weight', 'roberta.encoder.layer.6.attention.self.key.weight', 'roberta.encoder.layer.9.attention.output.dense.weight', 'roberta.encoder.layer.0.attention.self.value.bias', 'roberta.encoder.layer.10.output.LayerNorm.bias', 'roberta.encoder.layer.5.output.LayerNorm.bias', 'roberta.encoder.layer.4.attention.self.value.weight', 'roberta.encoder.layer.9.attention.output.LayerNorm.bias', 'roberta.encoder.layer.6.attention.self.query.weight', 'roberta.encoder.layer.11.attention.output.dense.weight', 'roberta.encoder.layer.0.attention.output.LayerNorm.bias', 'roberta.encoder.layer.0.intermediate.dense.bias', 'roberta.encoder.layer.5.attention.self.query.weight', 'roberta.encoder.layer.10.attention.self.key.weight', 'roberta.encoder.layer.1.attention.self.value.weight', 'roberta.encoder.layer.7.output.dense.bias', 'roberta.encoder.layer.8.intermediate.dense.weight', 'roberta.encoder.layer.8.attention.output.LayerNorm.bias', 'roberta.encoder.layer.11.intermediate.dense.bias', 'roberta.encoder.layer.6.attention.self.key.bias', 'roberta.encoder.layer.1.intermediate.dense.bias', 'roberta.encoder.layer.8.attention.self.key.weight', 'roberta.encoder.layer.10.output.LayerNorm.weight', 'roberta.encoder.layer.6.attention.output.dense.bias', 'roberta.encoder.layer.0.attention.self.query.bias', 'roberta.encoder.layer.5.attention.self.query.bias', 'roberta.encoder.layer.6.attention.self.query.bias', 'roberta.encoder.layer.6.output.dense.weight', 'roberta.encoder.layer.11.attention.output.LayerNorm.bias', 'roberta.encoder.layer.4.attention.self.query.weight', 'roberta.encoder.layer.8.output.dense.bias', 'roberta.encoder.layer.4.attention.self.query.bias', 'roberta.encoder.layer.7.attention.output.LayerNorm.weight', 'roberta.encoder.layer.5.attention.self.value.bias', 'roberta.encoder.layer.5.intermediate.dense.weight', 'roberta.encoder.layer.3.output.LayerNorm.bias', 'roberta.encoder.layer.10.attention.output.LayerNorm.weight', 'roberta.encoder.layer.3.attention.self.value.bias', 'roberta.encoder.layer.4.attention.self.key.bias', 'roberta.encoder.layer.3.attention.self.value.weight', 'roberta.encoder.layer.6.attention.output.LayerNorm.weight', 'roberta.encoder.layer.7.attention.self.value.weight', 'roberta.encoder.layer.7.attention.self.key.bias', 'roberta.encoder.layer.2.attention.self.query.weight', 'roberta.encoder.layer.4.attention.output.LayerNorm.bias', 'roberta.encoder.layer.4.output.dense.bias', 'roberta.encoder.layer.6.output.LayerNorm.bias', 'roberta.encoder.layer.1.output.dense.weight', 'roberta.encoder.layer.2.attention.self.query.bias', 'lm_head.decoder.weight', 'roberta.encoder.layer.11.attention.self.key.bias', 'roberta.encoder.layer.0.attention.output.dense.weight', 'roberta.encoder.layer.1.attention.output.LayerNorm.bias', 'roberta.encoder.layer.8.attention.self.key.bias', 'roberta.encoder.layer.7.attention.output.dense.bias', 'roberta.encoder.layer.11.attention.output.dense.bias', 'roberta.encoder.layer.5.attention.output.dense.bias', 'roberta.encoder.layer.6.intermediate.dense.bias', 'roberta.encoder.layer.3.attention.self.query.bias', 'roberta.encoder.layer.5.attention.self.key.bias', 'roberta.encoder.layer.0.attention.self.key.bias', 'roberta.encoder.layer.0.output.dense.weight', 'roberta.encoder.layer.4.attention.output.dense.bias', 'roberta.encoder.layer.9.attention.self.query.weight', 'roberta.encoder.layer.10.attention.output.LayerNorm.bias', 'roberta.encoder.layer.4.attention.output.LayerNorm.weight', 'roberta.encoder.layer.10.attention.self.key.bias', 'roberta.encoder.layer.4.attention.output.dense.weight', 'roberta.encoder.layer.8.attention.output.dense.weight', 'roberta.encoder.layer.8.attention.self.value.bias', 'roberta.encoder.layer.11.attention.output.LayerNorm.weight', 'roberta.encoder.layer.2.attention.output.LayerNorm.weight', 'lm_head.bias', 'roberta.encoder.layer.0.attention.self.key.weight', 'roberta.encoder.layer.9.output.LayerNorm.weight', 'roberta.encoder.layer.0.attention.self.query.weight', 'lm_head.dense.weight', 'roberta.encoder.layer.1.attention.self.query.weight', 'roberta.encoder.layer.2.attention.output.dense.weight', 'roberta.encoder.layer.2.output.dense.bias', 'roberta.encoder.layer.4.output.LayerNorm.bias', 'roberta.encoder.layer.7.attention.self.query.bias', 'roberta.encoder.layer.11.attention.self.value.weight', 'roberta.encoder.layer.7.attention.output.LayerNorm.bias', 'roberta.encoder.layer.9.attention.self.key.weight', 'lm_head.layer_norm.bias', 'roberta.encoder.layer.10.attention.self.value.weight', 'roberta.encoder.layer.6.attention.output.LayerNorm.bias', 'roberta.encoder.layer.11.attention.self.key.weight', 'roberta.encoder.layer.9.attention.output.dense.bias', 'roberta.pooler.dense.weight', 'roberta.encoder.layer.7.output.dense.weight', 'roberta.encoder.layer.8.attention.self.query.bias', 'roberta.encoder.layer.9.attention.output.LayerNorm.weight', 'roberta.encoder.layer.3.output.LayerNorm.weight', 'roberta.encoder.layer.6.output.LayerNorm.weight', 'roberta.encoder.layer.7.intermediate.dense.weight', 'roberta.encoder.layer.0.output.LayerNorm.bias', 'roberta.encoder.layer.11.output.dense.bias', 'roberta.encoder.layer.3.intermediate.dense.bias', 'roberta.encoder.layer.7.output.LayerNorm.weight', 'roberta.encoder.layer.7.attention.self.value.bias', 'roberta.encoder.layer.11.output.LayerNorm.weight', 'roberta.encoder.layer.1.output.LayerNorm.weight', 'roberta.encoder.layer.3.attention.output.dense.weight', 'roberta.encoder.layer.2.attention.self.key.bias', 'roberta.encoder.layer.10.attention.self.query.weight', 'roberta.encoder.layer.6.attention.self.value.bias', 'roberta.embeddings.word_embeddings.weight', 'roberta.encoder.layer.1.output.dense.bias', 'roberta.encoder.layer.8.output.dense.weight', 'roberta.embeddings.LayerNorm.bias', 'roberta.encoder.layer.1.attention.self.value.bias', 'roberta.encoder.layer.0.attention.self.value.weight', 'roberta.encoder.layer.9.attention.self.value.weight', 'roberta.encoder.layer.2.attention.self.value.bias', 'roberta.encoder.layer.11.attention.self.value.bias', 'roberta.encoder.layer.11.intermediate.dense.weight', 'roberta.embeddings.token_type_embeddings.weight', 'roberta.encoder.layer.5.output.LayerNorm.weight', 'roberta.encoder.layer.7.attention.output.dense.weight', 'roberta.encoder.layer.10.intermediate.dense.weight', 'roberta.encoder.layer.10.attention.output.dense.weight', 'roberta.encoder.layer.5.attention.output.dense.weight', 'roberta.encoder.layer.3.attention.self.query.weight', 'roberta.encoder.layer.6.output.dense.bias', 'roberta.encoder.layer.1.attention.self.query.bias', 'roberta.encoder.layer.3.output.dense.weight', 'roberta.encoder.layer.3.output.dense.bias', 'roberta.encoder.layer.9.output.LayerNorm.bias', 'roberta.encoder.layer.4.output.dense.weight', 'roberta.encoder.layer.10.intermediate.dense.bias', 'roberta.encoder.layer.5.attention.self.value.weight', 'roberta.encoder.layer.4.intermediate.dense.bias', 'roberta.encoder.layer.1.attention.output.dense.bias', 'roberta.embeddings.LayerNorm.weight', 'roberta.encoder.layer.7.intermediate.dense.bias', 'roberta.encoder.layer.9.output.dense.bias', 'roberta.encoder.layer.11.output.LayerNorm.bias', 'roberta.encoder.layer.6.attention.self.value.weight', 'roberta.encoder.layer.9.intermediate.dense.weight', 'roberta.encoder.layer.10.attention.self.query.bias', 'roberta.encoder.layer.10.output.dense.bias', 'roberta.encoder.layer.2.attention.output.LayerNorm.bias', 'roberta.encoder.layer.3.attention.output.dense.bias', 'roberta.encoder.layer.8.intermediate.dense.bias', 'roberta.encoder.layer.3.attention.self.key.bias', 'roberta.encoder.layer.3.attention.output.LayerNorm.bias', 'roberta.encoder.layer.8.output.LayerNorm.weight', 'roberta.encoder.layer.8.output.LayerNorm.bias', 'roberta.encoder.layer.2.intermediate.dense.weight', 'roberta.encoder.layer.5.attention.self.key.weight', 'roberta.encoder.layer.9.attention.self.key.bias', 'roberta.encoder.layer.11.output.dense.weight', 'roberta.encoder.layer.4.attention.self.value.bias', 'roberta.encoder.layer.7.attention.self.key.weight', 'roberta.encoder.layer.11.attention.self.query.bias', 'roberta.encoder.layer.9.attention.self.value.bias', 'roberta.encoder.layer.1.attention.output.dense.weight', 'roberta.encoder.layer.5.output.dense.weight', 'roberta.encoder.layer.1.output.LayerNorm.bias', 'roberta.encoder.layer.2.output.dense.weight', 'roberta.encoder.layer.0.attention.output.LayerNorm.weight', 'roberta.encoder.layer.7.attention.self.query.weight', 'roberta.encoder.layer.4.intermediate.dense.weight', 'roberta.embeddings.position_embeddings.weight', 'roberta.encoder.layer.9.output.dense.weight', 'roberta.encoder.layer.5.attention.output.LayerNorm.bias', 'roberta.encoder.layer.8.attention.output.dense.bias', 'roberta.encoder.layer.3.intermediate.dense.weight', 'roberta.encoder.layer.10.attention.output.dense.bias', 'roberta.encoder.layer.5.attention.output.LayerNorm.weight', 'roberta.encoder.layer.2.attention.self.value.weight', 'lm_head.layer_norm.weight', 'roberta.encoder.layer.8.attention.self.value.weight', 'roberta.encoder.layer.8.attention.output.LayerNorm.weight', 'roberta.encoder.layer.10.attention.self.value.bias', 'roberta.encoder.layer.0.output.LayerNorm.weight', 'roberta.encoder.layer.9.intermediate.dense.bias', 'roberta.encoder.layer.6.attention.output.dense.weight', 'roberta.encoder.layer.2.attention.output.dense.bias', 'roberta.encoder.layer.11.attention.self.query.weight', 'roberta.encoder.layer.0.output.dense.bias', 'roberta.encoder.layer.2.attention.self.key.weight', 'roberta.encoder.layer.4.attention.self.key.weight', 'roberta.encoder.layer.5.output.dense.bias', 'roberta.encoder.layer.3.attention.output.LayerNorm.weight']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at xlm-roberta-base and are newly initialized: ['encoder.layer.8.attention.self.value.weight', 'encoder.layer.10.attention.self.query.weight', 'encoder.layer.10.intermediate.dense.bias', 'encoder.layer.0.attention.self.key.weight', 'encoder.layer.4.attention.self.key.weight', 'encoder.layer.0.intermediate.dense.weight', 'encoder.layer.0.attention.output.LayerNorm.bias', 'encoder.layer.2.attention.output.dense.weight', 'encoder.layer.7.attention.output.dense.bias', 'encoder.layer.10.attention.self.key.weight', 'encoder.layer.5.output.LayerNorm.weight', 'encoder.layer.0.attention.self.key.bias', 'encoder.layer.7.attention.self.query.bias', 'encoder.layer.4.attention.self.query.weight', 'encoder.layer.1.attention.self.key.bias', 'encoder.layer.8.attention.output.dense.weight', 'encoder.layer.2.attention.self.key.bias', 'encoder.layer.6.attention.self.key.weight', 'embeddings.word_embeddings.weight', 'embeddings.LayerNorm.bias', 'encoder.layer.0.intermediate.dense.bias', 'encoder.layer.7.output.dense.weight', 'encoder.layer.3.attention.output.dense.weight', 'encoder.layer.7.attention.output.LayerNorm.weight', 'encoder.layer.0.attention.self.value.weight', 'encoder.layer.7.attention.self.query.weight', 'encoder.layer.2.attention.self.value.weight', 'encoder.layer.5.attention.self.query.weight', 'encoder.layer.11.intermediate.dense.weight', 'encoder.layer.1.attention.self.key.weight', 'encoder.layer.10.attention.output.dense.weight', 'encoder.layer.2.output.dense.weight', 'encoder.layer.11.output.LayerNorm.bias', 'encoder.layer.8.attention.output.LayerNorm.bias', 'encoder.layer.5.attention.output.LayerNorm.weight', 'encoder.layer.3.attention.self.value.weight', 'encoder.layer.5.attention.self.value.weight', 'encoder.layer.2.output.LayerNorm.bias', 'encoder.layer.0.output.LayerNorm.weight', 'encoder.layer.0.output.dense.bias', 'encoder.layer.0.output.dense.weight', 'encoder.layer.6.output.dense.weight', 'encoder.layer.5.attention.output.dense.weight', 'encoder.layer.4.intermediate.dense.bias', 'encoder.layer.8.intermediate.dense.weight', 'encoder.layer.7.output.LayerNorm.weight', 'encoder.layer.2.output.LayerNorm.weight', 'encoder.layer.1.attention.self.query.weight', 'embeddings.position_embeddings.weight', 'encoder.layer.4.output.LayerNorm.weight', 'encoder.layer.6.intermediate.dense.bias', 'encoder.layer.4.output.dense.bias', 'encoder.layer.3.intermediate.dense.weight', 'encoder.layer.10.attention.output.LayerNorm.bias', 'encoder.layer.7.attention.self.value.bias', 'encoder.layer.3.attention.self.query.bias', 'encoder.layer.5.attention.self.value.bias', 'encoder.layer.8.output.LayerNorm.bias', 'classifier.bias', 'embeddings.LayerNorm.weight', 'encoder.layer.0.output.LayerNorm.bias', 'encoder.layer.4.attention.self.key.bias', 'encoder.layer.7.attention.output.dense.weight', 'encoder.layer.7.attention.self.value.weight', 'encoder.layer.9.attention.output.LayerNorm.weight', 'encoder.layer.11.attention.self.value.weight', 'encoder.layer.3.output.LayerNorm.bias', 'encoder.layer.7.intermediate.dense.bias', 'encoder.layer.10.output.LayerNorm.bias', 'encoder.layer.2.intermediate.dense.weight', 'encoder.layer.11.intermediate.dense.bias', 'encoder.layer.9.attention.output.dense.weight', 'encoder.layer.11.attention.self.key.bias', 'pooler.dense.bias', 'encoder.layer.3.attention.self.query.weight', 'encoder.layer.9.attention.self.value.weight', 'encoder.layer.11.output.dense.bias', 'encoder.layer.11.attention.output.dense.bias', 'encoder.layer.5.attention.self.key.weight', 'encoder.layer.6.intermediate.dense.weight', 'encoder.layer.5.intermediate.dense.weight', 'encoder.layer.4.intermediate.dense.weight', 'encoder.layer.5.output.LayerNorm.bias', 'encoder.layer.1.attention.output.dense.weight', 'encoder.layer.3.intermediate.dense.bias', 'encoder.layer.1.attention.self.query.bias', 'encoder.layer.1.attention.output.LayerNorm.weight', 'encoder.layer.9.attention.output.dense.bias', 'encoder.layer.5.attention.output.LayerNorm.bias', 'encoder.layer.6.output.LayerNorm.bias', 'encoder.layer.7.attention.self.key.bias', 'encoder.layer.9.attention.self.query.bias', 'encoder.layer.8.attention.output.dense.bias', 'encoder.layer.1.output.dense.bias', 'encoder.layer.4.attention.self.query.bias', 'encoder.layer.9.output.LayerNorm.weight', 'encoder.layer.7.attention.output.LayerNorm.bias', 'encoder.layer.10.output.LayerNorm.weight', 'encoder.layer.11.attention.output.LayerNorm.weight', 'encoder.layer.0.attention.self.query.weight', 'encoder.layer.4.attention.self.value.bias', 'encoder.layer.3.output.dense.weight', 'encoder.layer.4.attention.self.value.weight', 'encoder.layer.4.attention.output.dense.weight', 'encoder.layer.6.attention.self.value.weight', 'encoder.layer.7.intermediate.dense.weight', 'encoder.layer.2.output.dense.bias', 'encoder.layer.10.attention.self.key.bias', 'encoder.layer.2.intermediate.dense.bias', 'encoder.layer.5.attention.self.key.bias', 'encoder.layer.2.attention.self.query.bias', 'encoder.layer.10.output.dense.bias', 'encoder.layer.1.output.LayerNorm.bias', 'encoder.layer.5.attention.self.query.bias', 'encoder.layer.6.attention.output.LayerNorm.bias', 'encoder.layer.9.attention.self.key.bias', 'encoder.layer.11.output.dense.weight', 'encoder.layer.1.attention.self.value.weight', 'encoder.layer.3.attention.output.dense.bias', 'encoder.layer.3.output.LayerNorm.weight', 'encoder.layer.6.output.dense.bias', 'encoder.layer.4.attention.output.LayerNorm.weight', 'encoder.layer.5.attention.output.dense.bias', 'encoder.layer.2.attention.output.LayerNorm.bias', 'encoder.layer.4.attention.output.LayerNorm.bias', 'encoder.layer.8.output.dense.weight', 'encoder.layer.10.attention.output.dense.bias', 'encoder.layer.1.output.dense.weight', 'encoder.layer.3.attention.self.value.bias', 'encoder.layer.8.attention.self.key.bias', 'encoder.layer.11.attention.self.key.weight', 'encoder.layer.11.attention.self.value.bias', 'encoder.layer.9.attention.self.key.weight', 'encoder.layer.11.attention.self.query.bias', 'encoder.layer.6.attention.self.key.bias', 'encoder.layer.1.intermediate.dense.weight', 'encoder.layer.7.output.LayerNorm.bias', 'encoder.layer.3.attention.self.key.weight', 'encoder.layer.6.attention.output.dense.weight', 'encoder.layer.8.attention.output.LayerNorm.weight', 'encoder.layer.8.attention.self.query.weight', 'encoder.layer.9.output.dense.weight', 'encoder.layer.6.attention.output.dense.bias', 'encoder.layer.10.intermediate.dense.weight', 'encoder.layer.10.attention.self.value.bias', 'encoder.layer.3.attention.output.LayerNorm.bias', 'classifier.weight', 'encoder.layer.9.attention.self.query.weight', 'encoder.layer.2.attention.self.value.bias', 'encoder.layer.2.attention.self.query.weight', 'encoder.layer.1.attention.self.value.bias', 'encoder.layer.11.attention.output.dense.weight', 'encoder.layer.5.intermediate.dense.bias', 'encoder.layer.9.output.LayerNorm.bias', 'pooler.dense.weight', 'encoder.layer.8.intermediate.dense.bias', 'encoder.layer.6.attention.self.value.bias', 'encoder.layer.2.attention.self.key.weight', 'encoder.layer.8.attention.self.query.bias', 'encoder.layer.0.attention.self.value.bias', 'encoder.layer.4.output.dense.weight', 'encoder.layer.2.attention.output.dense.bias', 'encoder.layer.10.output.dense.weight', 'encoder.layer.5.output.dense.weight', 'encoder.layer.9.attention.output.LayerNorm.bias', 'encoder.layer.8.output.LayerNorm.weight', 'encoder.layer.0.attention.output.dense.weight', 'encoder.layer.1.attention.output.dense.bias', 'encoder.layer.9.output.dense.bias', 'encoder.layer.6.attention.self.query.bias', 'encoder.layer.7.attention.self.key.weight', 'encoder.layer.3.attention.self.key.bias', 'encoder.layer.10.attention.output.LayerNorm.weight', 'encoder.layer.3.attention.output.LayerNorm.weight', 'encoder.layer.2.attention.output.LayerNorm.weight', 'encoder.layer.1.attention.output.LayerNorm.bias', 'encoder.layer.0.attention.output.LayerNorm.weight', 'encoder.layer.8.output.dense.bias', 'encoder.layer.11.attention.self.query.weight', 'encoder.layer.0.attention.self.query.bias', 'encoder.layer.10.attention.self.value.weight', 'encoder.layer.6.attention.output.LayerNorm.weight', 'encoder.layer.10.attention.self.query.bias', 'embeddings.token_type_embeddings.weight', 'encoder.layer.6.attention.self.query.weight', 'encoder.layer.7.output.dense.bias', 'encoder.layer.1.output.LayerNorm.weight', 'encoder.layer.8.attention.self.value.bias', 'encoder.layer.9.attention.self.value.bias', 'encoder.layer.4.attention.output.dense.bias', 'encoder.layer.9.intermediate.dense.weight', 'encoder.layer.5.output.dense.bias', 'encoder.layer.6.output.LayerNorm.weight', 'encoder.layer.1.intermediate.dense.bias', 'encoder.layer.9.intermediate.dense.bias', 'encoder.layer.3.output.dense.bias', 'encoder.layer.8.attention.self.key.weight', 'encoder.layer.11.attention.output.LayerNorm.bias', 'encoder.layer.11.output.LayerNorm.weight', 'encoder.layer.4.output.LayerNorm.bias', 'encoder.layer.0.attention.output.dense.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_BY-1Ubg8vzT"
      },
      "source": [
        "train_encodings = tokenizer(train_texts, truncation=True, padding=True)\n",
        "val_encodings = tokenizer(val_texts, truncation=True, padding=True)\n",
        "test_encodings = tokenizer(text_test, truncation=True, padding=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C9174BnI8vzU"
      },
      "source": [
        "train_dataset = FUNDSDataset(train_encodings, train_labels)\n",
        "val_dataset = FUNDSDataset(val_encodings, val_labels)\n",
        "test_dataset = FUNDSDataset(test_encodings, labels_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3_YfkHum4b3J"
      },
      "source": [
        "#### Training arguments:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oM9OAKa5pvVM"
      },
      "source": [
        "args = TrainingArguments(\n",
        "    output_dir='./results',\n",
        "    evaluation_strategy = \"epoch\",\n",
        "    save_strategy='epoch',\n",
        "    learning_rate=2e-5,\n",
        "    per_device_train_batch_size=16,\n",
        "    per_device_eval_batch_size=8,\n",
        "    num_train_epochs=6,\n",
        "    weight_decay=0.01,\n",
        "    load_best_model_at_end=True,\n",
        "    metric_for_best_model='f1',\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SfeAlTPlpvVM"
      },
      "source": [
        "trainer = Trainer(\n",
        "    model,\n",
        "    args,\n",
        "    train_dataset=train_dataset,\n",
        "    eval_dataset=val_dataset,\n",
        "    tokenizer=tokenizer,\n",
        "    compute_metrics=compute_metrics\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rS9w8dtB4fbM"
      },
      "source": [
        "### Entrenamiento"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "v-bhukt2pvVN",
        "outputId": "c7b9581c-a17b-42b1-9937-eada75f719ac"
      },
      "source": [
        "trainer.train() "
      ],
      "execution_count": null,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "***** Running training *****\n",
            "  Num examples = 10502\n",
            "  Num Epochs = 6\n",
            "  Instantaneous batch size per device = 16\n",
            "  Total train batch size (w. parallel, distributed & accumulation) = 16\n",
            "  Gradient Accumulation steps = 1\n",
            "  Total optimization steps = 3942\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  if __name__ == '__main__':\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='2501' max='3942' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [2501/3942 44:49 < 25:50, 0.93 it/s, Epoch 3.81/6]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>F1</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.540900</td>\n",
              "      <td>0.536175</td>\n",
              "      <td>0.786748</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.542600</td>\n",
              "      <td>0.528542</td>\n",
              "      <td>0.789414</td>\n",
              "      <td>0.024691</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.012500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.513300</td>\n",
              "      <td>0.508967</td>\n",
              "      <td>0.791318</td>\n",
              "      <td>0.151703</td>\n",
              "      <td>0.569767</td>\n",
              "      <td>0.087500</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "***** Running Evaluation *****\n",
            "  Num examples = 2626\n",
            "  Batch size = 8\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "Saving model checkpoint to ./results/checkpoint-657\n",
            "Configuration saved in ./results/checkpoint-657/config.json\n",
            "Model weights saved in ./results/checkpoint-657/pytorch_model.bin\n",
            "tokenizer config file saved in ./results/checkpoint-657/tokenizer_config.json\n",
            "Special tokens file saved in ./results/checkpoint-657/special_tokens_map.json\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  if __name__ == '__main__':\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 2626\n",
            "  Batch size = 8\n",
            "Saving model checkpoint to ./results/checkpoint-1314\n",
            "Configuration saved in ./results/checkpoint-1314/config.json\n",
            "Model weights saved in ./results/checkpoint-1314/pytorch_model.bin\n",
            "tokenizer config file saved in ./results/checkpoint-1314/tokenizer_config.json\n",
            "Special tokens file saved in ./results/checkpoint-1314/special_tokens_map.json\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  if __name__ == '__main__':\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 2626\n",
            "  Batch size = 8\n",
            "Saving model checkpoint to ./results/checkpoint-1971\n",
            "Configuration saved in ./results/checkpoint-1971/config.json\n",
            "Model weights saved in ./results/checkpoint-1971/pytorch_model.bin\n",
            "tokenizer config file saved in ./results/checkpoint-1971/tokenizer_config.json\n",
            "Special tokens file saved in ./results/checkpoint-1971/special_tokens_map.json\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  if __name__ == '__main__':\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='3942' max='3942' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [3942/3942 1:12:55, Epoch 6/6]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>F1</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.540900</td>\n",
              "      <td>0.536175</td>\n",
              "      <td>0.786748</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.542600</td>\n",
              "      <td>0.528542</td>\n",
              "      <td>0.789414</td>\n",
              "      <td>0.024691</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.012500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.513300</td>\n",
              "      <td>0.508967</td>\n",
              "      <td>0.791318</td>\n",
              "      <td>0.151703</td>\n",
              "      <td>0.569767</td>\n",
              "      <td>0.087500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.477400</td>\n",
              "      <td>0.530212</td>\n",
              "      <td>0.790937</td>\n",
              "      <td>0.148837</td>\n",
              "      <td>0.564706</td>\n",
              "      <td>0.085714</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.458000</td>\n",
              "      <td>0.558091</td>\n",
              "      <td>0.770373</td>\n",
              "      <td>0.221935</td>\n",
              "      <td>0.400000</td>\n",
              "      <td>0.153571</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>0.450500</td>\n",
              "      <td>0.551587</td>\n",
              "      <td>0.768469</td>\n",
              "      <td>0.220513</td>\n",
              "      <td>0.390909</td>\n",
              "      <td>0.153571</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "***** Running Evaluation *****\n",
            "  Num examples = 2626\n",
            "  Batch size = 8\n",
            "Saving model checkpoint to ./results/checkpoint-2628\n",
            "Configuration saved in ./results/checkpoint-2628/config.json\n",
            "Model weights saved in ./results/checkpoint-2628/pytorch_model.bin\n",
            "tokenizer config file saved in ./results/checkpoint-2628/tokenizer_config.json\n",
            "Special tokens file saved in ./results/checkpoint-2628/special_tokens_map.json\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  if __name__ == '__main__':\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 2626\n",
            "  Batch size = 8\n",
            "Saving model checkpoint to ./results/checkpoint-3285\n",
            "Configuration saved in ./results/checkpoint-3285/config.json\n",
            "Model weights saved in ./results/checkpoint-3285/pytorch_model.bin\n",
            "tokenizer config file saved in ./results/checkpoint-3285/tokenizer_config.json\n",
            "Special tokens file saved in ./results/checkpoint-3285/special_tokens_map.json\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  if __name__ == '__main__':\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 2626\n",
            "  Batch size = 8\n",
            "Saving model checkpoint to ./results/checkpoint-3942\n",
            "Configuration saved in ./results/checkpoint-3942/config.json\n",
            "Model weights saved in ./results/checkpoint-3942/pytorch_model.bin\n",
            "tokenizer config file saved in ./results/checkpoint-3942/tokenizer_config.json\n",
            "Special tokens file saved in ./results/checkpoint-3942/special_tokens_map.json\n",
            "\n",
            "\n",
            "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
            "\n",
            "\n",
            "Loading best model from ./results/checkpoint-3285 (score: 0.22193548387096776).\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TrainOutput(global_step=3942, training_loss=0.4909772016504947, metrics={'train_runtime': 4376.2995, 'train_samples_per_second': 14.398, 'train_steps_per_second': 0.901, 'total_flos': 5148604409052240.0, 'train_loss': 0.4909772016504947, 'epoch': 6.0})"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rPY77QdItBYe"
      },
      "source": [
        "Saving the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-0EyXuftjojj",
        "outputId": "93c22f21-e576-4884-c06f-6b8548bcb04b"
      },
      "source": [
        "trainer.save_model('RoBerta')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Saving model checkpoint to RoBerta\n",
            "Configuration saved in RoBerta/config.json\n",
            "Model weights saved in RoBerta/pytorch_model.bin\n",
            "tokenizer config file saved in RoBerta/tokenizer_config.json\n",
            "Special tokens file saved in RoBerta/special_tokens_map.json\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4XK7r9fLj1Pq",
        "outputId": "a17cb75b-c72b-499c-c485-640387462266"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "vCwlmRkfj_mj",
        "outputId": "ff59d45f-a11d-49af-ebbf-c6fc665f27f7"
      },
      "source": [
        "import shutil\n",
        "shutil.make_archive('/content/drive/MyDrive/RoBerta', 'zip', 'RoBerta')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'/content/drive/MyDrive/RoBerta.zip'"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9MMI8-44qnga"
      },
      "source": [
        "## Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 315
        },
        "id": "8RM-BCErHyBL",
        "outputId": "88380ffd-0967-4247-8e74-a952a688b23a"
      },
      "source": [
        "trainer.evaluate(test_dataset)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "***** Running Evaluation *****\n",
            "  Num examples = 2110\n",
            "  Batch size = 8\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  if __name__ == '__main__':\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='264' max='264' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [264/264 00:51]\n",
              "    </div>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'epoch': 3.0,\n",
              " 'eval_accuracy': 0.6341232227488152,\n",
              " 'eval_f1': 0.38632750397456284,\n",
              " 'eval_loss': 0.6881266236305237,\n",
              " 'eval_precision': 0.43548387096774194,\n",
              " 'eval_recall': 0.34714285714285714,\n",
              " 'eval_runtime': 51.9692,\n",
              " 'eval_samples_per_second': 40.601,\n",
              " 'eval_steps_per_second': 5.08}"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RYwA_OjN4tcW"
      },
      "source": [
        "## Downloading and loading the trained weights"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ECF7JzhDRtNl",
        "outputId": "4d2eafba-a8b0-47d4-a22e-0c55684bb311",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "import shutil\n",
        "!wget https://www.dropbox.com/s/639xxc3o7v9ena8/RoBerta.zip\n",
        "!unzip RoBerta.zip"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2021-10-15 07:13:15--  https://www.dropbox.com/s/639xxc3o7v9ena8/RoBerta.zip\n",
            "Resolving www.dropbox.com (www.dropbox.com)... 162.125.3.18, 2620:100:601b:18::a27d:812\n",
            "Connecting to www.dropbox.com (www.dropbox.com)|162.125.3.18|:443... connected.\n",
            "HTTP request sent, awaiting response... 301 Moved Permanently\n",
            "Location: /s/raw/639xxc3o7v9ena8/RoBerta.zip [following]\n",
            "--2021-10-15 07:13:15--  https://www.dropbox.com/s/raw/639xxc3o7v9ena8/RoBerta.zip\n",
            "Reusing existing connection to www.dropbox.com:443.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://ucc14d15ddfc4798d63d35eabfba.dl.dropboxusercontent.com/cd/0/inline/BYGPko5VSprSX_fZrm7WYL9lbM3dQp7GaKGxrT4C-NlTo6d5f1kKTJYKs5tGELFd1KMlnJsw8dmEtVqW1NxOvAGUFtP_fOz43hw3WfM8lwKe_rjI6V21GtpIKQ5cghB0yOVwmTG8fCjPO_kOw9w9X11E/file# [following]\n",
            "--2021-10-15 07:13:15--  https://ucc14d15ddfc4798d63d35eabfba.dl.dropboxusercontent.com/cd/0/inline/BYGPko5VSprSX_fZrm7WYL9lbM3dQp7GaKGxrT4C-NlTo6d5f1kKTJYKs5tGELFd1KMlnJsw8dmEtVqW1NxOvAGUFtP_fOz43hw3WfM8lwKe_rjI6V21GtpIKQ5cghB0yOVwmTG8fCjPO_kOw9w9X11E/file\n",
            "Resolving ucc14d15ddfc4798d63d35eabfba.dl.dropboxusercontent.com (ucc14d15ddfc4798d63d35eabfba.dl.dropboxusercontent.com)... 162.125.3.15, 2620:100:601b:15::a27d:80f\n",
            "Connecting to ucc14d15ddfc4798d63d35eabfba.dl.dropboxusercontent.com (ucc14d15ddfc4798d63d35eabfba.dl.dropboxusercontent.com)|162.125.3.15|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: /cd/0/inline2/BYGYqJUQ59M3P2tNxy9Gc2GXNaBjkViZQe4x3ONqFXf6ps0vdvl0rE3ta80GFEoYv8hQuXgGhBr2tMEWIDH0rddBnQgHf-2C9j07jw1Cd7TMDYOybV54ICsW3tScvpa68LEYkHV93t_GvnUwNjFpgiWxbTf3oCq0ngOEiHGyN5-60k_saLb11ZIBL2ZZjNHXxDWAsashNzq_sdy2cvv3N__XnHAydQwKFcOU47n701WuRspTmYxT1yfrKWp537FzrSSlKPMPDHNqR9fsuw6lcBlidSnCKbX5ZaQyol3Vw5eXYE1iluYU1X1tGAJbcaf2TsMdWAvR_9nkZinBEl1b6_KXCJZK0E6289W7Y6KbUuerBAgWIprInjEPKx0kBYOJQIY/file [following]\n",
            "--2021-10-15 07:13:15--  https://ucc14d15ddfc4798d63d35eabfba.dl.dropboxusercontent.com/cd/0/inline2/BYGYqJUQ59M3P2tNxy9Gc2GXNaBjkViZQe4x3ONqFXf6ps0vdvl0rE3ta80GFEoYv8hQuXgGhBr2tMEWIDH0rddBnQgHf-2C9j07jw1Cd7TMDYOybV54ICsW3tScvpa68LEYkHV93t_GvnUwNjFpgiWxbTf3oCq0ngOEiHGyN5-60k_saLb11ZIBL2ZZjNHXxDWAsashNzq_sdy2cvv3N__XnHAydQwKFcOU47n701WuRspTmYxT1yfrKWp537FzrSSlKPMPDHNqR9fsuw6lcBlidSnCKbX5ZaQyol3Vw5eXYE1iluYU1X1tGAJbcaf2TsMdWAvR_9nkZinBEl1b6_KXCJZK0E6289W7Y6KbUuerBAgWIprInjEPKx0kBYOJQIY/file\n",
            "Reusing existing connection to ucc14d15ddfc4798d63d35eabfba.dl.dropboxusercontent.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1035190541 (987M) [application/zip]\n",
            "Saving to: ‘RoBerta.zip’\n",
            "\n",
            "RoBerta.zip         100%[===================>] 987.23M  78.1MB/s    in 13s     \n",
            "\n",
            "2021-10-15 07:13:29 (76.1 MB/s) - ‘RoBerta.zip’ saved [1035190541/1035190541]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YSRQvX3QRtNl"
      },
      "source": [
        "from transformers import BertForSequenceClassification,AutoTokenizer,Trainer, TrainingArguments\n",
        "tokenizer = AutoTokenizer.from_pretrained('RoBerta')\n",
        "model = BertForSequenceClassification.from_pretrained('RoBerta', num_labels=2)\n",
        "trainer = Trainer(model,compute_metrics=compute_metrics)"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FqnJOgkX2nnc"
      },
      "source": [
        "# Results"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cDlApZq8uwij"
      },
      "source": [
        "We build our test dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4km8oIFjuhAA"
      },
      "source": [
        "dataset_test=Dataset('dataset/testing_data/annotations')\n",
        "text_test, labels_test=dataset_test.preparation()\n",
        "test_encodings = tokenizer(text_test, truncation=True, padding=True)\n",
        "test_dataset = FUNDSDataset(test_encodings, labels_test)"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mTO31eesiFVN"
      },
      "source": [
        "**We check if all the answers have at least one question in their candidates:**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5iufGy2jiKE9",
        "outputId": "cf4313c5-caa6-4442-f744-9d31e1467168"
      },
      "source": [
        "path='/content/dataset/testing_data/annotations/'\n",
        "i=0\n",
        "for f in dataset_test:\n",
        "  f=path+f\n",
        "  cand,_,_=candidatesANDlabels(f)\n",
        "  for c in cand:\n",
        "    if cand[c]==[]:\n",
        "      i+=1\n",
        "print(i)"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e0b3G_kjiSds"
      },
      "source": [
        "There's no answer without candidates"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5ZIkTrnCiFVN"
      },
      "source": [
        "**We check if all the correct questions are in the candidate list of the answer:**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GJVKorY2iZR9",
        "outputId": "3f0d73c9-67ee-49d9-83e4-182b962626b6"
      },
      "source": [
        "path='/content/dataset/testing_data/annotations/'\n",
        "i,j=0,0\n",
        "for f in dataset_test:\n",
        "  f=path+f\n",
        "  _,lbl,_=candidatesANDlabels(f)\n",
        "  for k in lbl:\n",
        "    j+=1\n",
        "    if not(True in lbl[k]):\n",
        "      i+=1\n",
        "print(i,j)"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3 821\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kWO4pX3-iZR-",
        "outputId": "1cef9220-9258-4209-b4ab-1abaa53bb68c"
      },
      "source": [
        "3*100/821"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.3654080389768575"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H0HHQTISiFVO"
      },
      "source": [
        "Ther're 3 of the 821 answers (0.37%) who haven't got their correct question in the candidates"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "94lXrlBaksoA"
      },
      "source": [
        "### PREDICTIONS"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VpYIaKpnQv9O",
        "outputId": "d85dc382-6096-45ba-a901-0d8179d599bf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 142
        }
      },
      "source": [
        "coef=trainer.predict(test_dataset)[0]\n",
        "prediction=coef.argmax(-1)\n",
        "prediction=[p for p in prediction]\n",
        "coef=[tupla[1] for tupla in coef]"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "***** Running Prediction *****\n",
            "  Num examples = 4002\n",
            "  Batch size = 8\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  if __name__ == '__main__':\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='501' max='501' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [501/501 01:42]\n",
              "    </div>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fi-UJlq-ExUH"
      },
      "source": [
        "### Results (Before the rules are applied)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kyy_aMYwzckn",
        "outputId": "8fc77892-28c0-4a2c-f300-75e40beeccdf"
      },
      "source": [
        "precision, recall, f1, _ = precision_recall_fscore_support(labels_test, prediction, average='binary')\n",
        "acc = accuracy_score(labels_test, prediction)\n",
        "print('accuracy: ',acc)\n",
        "print('precision: ',precision)\n",
        "print('recall: ',recall)\n",
        "print('f1: ',f1)"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "accuracy:  0.7626186906546727\n",
            "precision:  0.34366925064599485\n",
            "recall:  0.16043425814234016\n",
            "f1:  0.21875\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z_Z1FpCNkAGu",
        "outputId": "9640eba0-5545-4aab-c9af-5ea66314eced"
      },
      "source": [
        "mAP(dataset_test,coef,labels_test)"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_ranking.py:677: RuntimeWarning: invalid value encountered in true_divide\n",
            "  recall = tps / tps[-1]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.5822398774591209"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h1hXa4EbkAG5",
        "outputId": "3e023890-ff90-4026-89b6-b39c105e5a02"
      },
      "source": [
        "mRank(dataset_test,prediction,labels_test,coef)"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1.5529841656516443"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kcDnmj5Vkkys"
      },
      "source": [
        "### Results (After the rules are applied)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xkWlrFU4XfJK"
      },
      "source": [
        "def rules(cand, pred,coef):\n",
        "  i=0\n",
        "  pred_FINAL,coef_FINAL=[],[]\n",
        "  for c in cand:\n",
        "    j=i+len(cand[c])\n",
        "    new_pred=pred[i:j]\n",
        "    new_coef=coef[i:j]\n",
        "    if new_pred!=[]:\n",
        "      if 1 in new_pred:\n",
        "        encontrado=False\n",
        "        m=0\n",
        "        while encontrado==False:\n",
        "          if new_pred[m]==1:\n",
        "            encontrado=True\n",
        "            new_coef[m]=10\n",
        "          m+=1\n",
        "        for k in range(m,j-i):\n",
        "          new_pred[k]=0\n",
        "      else:\n",
        "        new_pred[0]=1\n",
        "        new_coef[0]=10\n",
        "      i=j\n",
        "      pred_FINAL=pred_FINAL+new_pred\n",
        "      coef_FINAL=coef_FINAL+new_coef\n",
        "  return pred_FINAL,coef_FINAL"
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gXWsD7w9h5XB"
      },
      "source": [
        "RULES:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u62UW6MpbwqC"
      },
      "source": [
        "path=dataset_test.path_annotation+'/'\n",
        "a=0\n",
        "prediction_FINAL,coef_FINAL=[],[]\n",
        "for f in dataset_test:\n",
        "  cand,txt=rank(path+f)\n",
        "  lenght=0\n",
        "  for c in cand:\n",
        "    lenght+=len(cand[c])\n",
        "  b=a+lenght\n",
        "  pred,cf=rules(cand, prediction[a:b],coef[a:b])\n",
        "  prediction_FINAL=prediction_FINAL+pred\n",
        "  coef_FINAL=coef_FINAL+cf\n",
        "  a=b"
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XDrpP2l08PBM",
        "outputId": "e5d65854-4f9f-4606-a7d0-4aaa888c1184"
      },
      "source": [
        "precision, recall, f1, _ = precision_recall_fscore_support(labels_test, prediction_FINAL, average='binary')\n",
        "acc = accuracy_score(labels_test, prediction_FINAL)\n",
        "print('accuracy: ',acc)\n",
        "print('precision: ',precision)\n",
        "print('recall: ',recall)\n",
        "print('f1: ',f1)"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "accuracy:  0.8585707146426786\n",
            "precision:  0.6601705237515225\n",
            "recall:  0.6537997587454765\n",
            "f1:  0.656969696969697\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WB4NWugU6m1D",
        "outputId": "d66e4138-f9c5-45ea-dbaf-d12b04b615f4"
      },
      "source": [
        "mAP(dataset_test,coef_FINAL,labels_test)"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_ranking.py:677: RuntimeWarning: invalid value encountered in true_divide\n",
            "  recall = tps / tps[-1]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.7681850697685044"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g-oA4RxpRxW4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "515901ad-e806-488a-8f55-1edf8514275c"
      },
      "source": [
        "mRank(dataset_test,prediction_FINAL,labels_test,coef_FINAL)"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9366626065773447"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    }
  ]
}