{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "EntLink_Bert.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "ghKTiGzgvicT",
        "txCNhgh3IcP-",
        "7pQub9q-p-w4",
        "K80KuBLOGmhx",
        "ofrsuUEuGmiG"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mavillot/FUNSD-Entity-Linking/blob/main/Bert.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eoWYsfAj5KrP"
      },
      "source": [
        "# Language model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jv2NEZ_XAlQ-"
      },
      "source": [
        "## Data preparation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9jNuJScWvS58"
      },
      "source": [
        "### Dataset:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5sZiqEN1tArs"
      },
      "source": [
        "%%capture\n",
        "!wget https://guillaumejaume.github.io/FUNSD/dataset.zip -O dataset.zip\n",
        "!unzip dataset.zip"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K80KuBLOGmhx"
      },
      "source": [
        "### Extracting candidates "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yYcsCwBK0F6X"
      },
      "source": [
        "import json\n",
        "from pathlib import Path\n",
        "import cv2\n",
        "import numpy as np"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lgCFh_RnGmiD"
      },
      "source": [
        "def candidates(path):\n",
        "  anot=json.loads(open(path).read())\n",
        "  img=Path(path).stem+'.png'\n",
        "  path_image=Path(path).parent.parent/'images'/img\n",
        "  h,w,_=cv2.imread(str(path_image)).shape\n",
        "  question, answer=[],[]\n",
        "  text={}\n",
        "  for block in anot['form']:\n",
        "    if block['label']=='question':\n",
        "      question.append([block['id'],block['box']])\n",
        "      text[block['id']]=block['text']\n",
        "    if block['label']=='answer':\n",
        "      answer.append([block['id'],block['box']])\n",
        "      text[block['id']]=block['text']\n",
        "  # We have built 2 list with answers and questions' info \n",
        "  #For each answer we look for its question\n",
        "  dic={}\n",
        "  for a in answer:\n",
        "    bbox=a[1]\n",
        "    candidates=[]\n",
        "    candidates_more=[]\n",
        "    x_a=int(bbox[0])\n",
        "    x1_a=int(bbox[2])\n",
        "    y_a=int(bbox[1])\n",
        "    y1_a=int(bbox[3])\n",
        "    pto_a=[(x_a+x1_a)/2,(y_a+y1_a)/2]\n",
        "    for q in question:\n",
        "      bbox=q[1]\n",
        "      x_q=int(bbox[0])\n",
        "      x1_q=int(bbox[2])\n",
        "      y_q=int(bbox[1])\n",
        "      y1_q=int(bbox[3])\n",
        "      pto_q=[(x_q+x1_q)/2,(y_q+y1_q)/2]\n",
        "      if x_q<x1_a+0.05*w and y1_q>y_a-0.1*h and y_q<y1_a+0.01*h:\n",
        "        dist=np.sqrt((x_a-x1_q)**2+(pto_a[1]-pto_q[1])**2)\n",
        "        candidates.append([q[0],dist])\n",
        "      if x_q<x1_a +0.05*w and y1_q>y_a-0.6*h and y_q<y1_a+0.03*h:\n",
        "        dist=np.sqrt((x_a-x1_q)**2+(pto_a[1]-pto_q[1])**2)\n",
        "        candidates_more.append([q[0],dist])\n",
        "    if candidates!=[]:\n",
        "      dic[a[0]]=candidates\n",
        "    else:\n",
        "      dic[a[0]]=candidates_more\n",
        "  return dic,text"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P50Ykdn3GmiF",
        "outputId": "fb1cc5f2-87f2-43c1-d24e-d7b539bedf36"
      },
      "source": [
        "candidates('dataset/training_data/annotations/0000971160.json')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "({4: [[1, 286.05287972680856],\n",
              "   [3, 41.593268686170845],\n",
              "   [10, 309.0457085934053],\n",
              "   [13, 20.006249023742555],\n",
              "   [15, 293.0959740426334]],\n",
              "  11: [[3, 303.0264014900352], [10, 11.10180165558726]],\n",
              "  12: [[3, 25.243811122728676], [10, 339.1194479825656]],\n",
              "  14: [[1, 11.10180165558726],\n",
              "   [10, 50.835519078691426],\n",
              "   [15, 18.33712082089225]],\n",
              "  16: [[1, 82.76472678623425],\n",
              "   [2, 39.96248240537617],\n",
              "   [3, 349.7802881810237],\n",
              "   [10, 116.84177335182824],\n",
              "   [13, 311.4498354470588],\n",
              "   [15, 78.18567643756751]],\n",
              "  18: [[17, 26.419689627245813]],\n",
              "  21: [[5, 15.402921800749363],\n",
              "   [6, 254.32656172724074],\n",
              "   [7, 333.7813655673426],\n",
              "   [20, 21.587033144922902]],\n",
              "  22: [[5, 118.71394189394942], [20, 112.58885380000989]]},\n",
              " {1: ':',\n",
              "  2: 'Suggestion:',\n",
              "  3: 'Date:',\n",
              "  4: 'Licensee',\n",
              "  5: '',\n",
              "  6: 'Yes',\n",
              "  7: 'No',\n",
              "  10: 'Name / Phone Ext. :',\n",
              "  11: 'M. Hamann P. Harper, P. Martinez',\n",
              "  12: '9/ 3/ 92',\n",
              "  13: 'R&D Group:',\n",
              "  14: 'J. S. Wigand',\n",
              "  15: 'Supervisor / Manager',\n",
              "  16: 'Discontinue coal retention analyses on licensee submitted product samples (Note : Coal Retention testing is not performed by most licensees. Other B&W physical measurements as ends stability and inspection for soft spots in ciparettes are thought to be sufficient measures to assure cigarette physical integrity. The proposed action will increase laboratory productivity . )',\n",
              "  17: 'Suggested Solutions (s) :',\n",
              "  18: 'Delete coal retention from the list of standard analyses performed on licensee submitted product samples. Special requests for coal retention testing could still be submitted on an exception basis.',\n",
              "  20: 'Manager Comments:',\n",
              "  21: 'Manager, please contact suggester and forward',\n",
              "  22: 'comments to the Quality Council.'})"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IT5CSGNWK0y8"
      },
      "source": [
        "We rank the candidates according to the distance"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wlj81pRnPdEG"
      },
      "source": [
        "from operator import itemgetter"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yB0B99CmK0cS"
      },
      "source": [
        "def rank(path):\n",
        "  cand,text=candidates(path)\n",
        "  for c in cand:\n",
        "    aux=cand[c]\n",
        "    cand[c]=[l[0] for l in sorted(aux, key=itemgetter(1))]\n",
        "  return cand,text"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xa2BZOTaMfpE",
        "outputId": "d1aa8de0-d0df-4d80-903c-bfbb0dea5e56"
      },
      "source": [
        "rank('dataset/training_data/annotations/0000971160.json')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "({4: [13, 3, 1, 15, 10],\n",
              "  11: [10, 3],\n",
              "  12: [3, 10],\n",
              "  14: [1, 15, 10],\n",
              "  16: [2, 15, 1, 10, 13, 3],\n",
              "  18: [17],\n",
              "  21: [5, 20, 6, 7],\n",
              "  22: [20, 5]},\n",
              " {1: ':',\n",
              "  2: 'Suggestion:',\n",
              "  3: 'Date:',\n",
              "  4: 'Licensee',\n",
              "  5: '',\n",
              "  6: 'Yes',\n",
              "  7: 'No',\n",
              "  10: 'Name / Phone Ext. :',\n",
              "  11: 'M. Hamann P. Harper, P. Martinez',\n",
              "  12: '9/ 3/ 92',\n",
              "  13: 'R&D Group:',\n",
              "  14: 'J. S. Wigand',\n",
              "  15: 'Supervisor / Manager',\n",
              "  16: 'Discontinue coal retention analyses on licensee submitted product samples (Note : Coal Retention testing is not performed by most licensees. Other B&W physical measurements as ends stability and inspection for soft spots in ciparettes are thought to be sufficient measures to assure cigarette physical integrity. The proposed action will increase laboratory productivity . )',\n",
              "  17: 'Suggested Solutions (s) :',\n",
              "  18: 'Delete coal retention from the list of standard analyses performed on licensee submitted product samples. Special requests for coal retention testing could still be submitted on an exception basis.',\n",
              "  20: 'Manager Comments:',\n",
              "  21: 'Manager, please contact suggester and forward',\n",
              "  22: 'comments to the Quality Council.'})"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ofrsuUEuGmiG"
      },
      "source": [
        "We construct now a function that given a path it returns for each answer the candidates, the labels and the text of the questions and answers"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vqNb6yjyGmiG"
      },
      "source": [
        "def candidatesANDlabels(path):\n",
        "  anot=json.loads(open(path).read())\n",
        "  cand,text=rank(path)\n",
        "  dic_label={}\n",
        "  for block in anot['form']:\n",
        "    if block['label']=='answer':\n",
        "      id=block['id']\n",
        "      id_question=[]\n",
        "      for link in block['linking']:\n",
        "        if link[0]==id:\n",
        "          id_question.append(link[1])\n",
        "        else: id_question.append(link[0])\n",
        "      lista=cand[id]\n",
        "      labels=[lista[i] in id_question for i in range(0,len(lista))]\n",
        "      dic_label[id]=labels\n",
        "  return cand,dic_label,text     "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gBMh6IjYGmiH",
        "outputId": "6c31c08d-4e6b-48fb-f438-837ddc944975"
      },
      "source": [
        "candidatesANDlabels('dataset/training_data/annotations/0000971160.json')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "({4: [13, 3, 1, 15, 10],\n",
              "  11: [10, 3],\n",
              "  12: [3, 10],\n",
              "  14: [1, 15, 10],\n",
              "  16: [2, 15, 1, 10, 13, 3],\n",
              "  18: [17],\n",
              "  21: [5, 20, 6, 7],\n",
              "  22: [20, 5]},\n",
              " {4: [True, False, False, False, False],\n",
              "  11: [True, False],\n",
              "  12: [True, False],\n",
              "  14: [False, True, False],\n",
              "  16: [True, False, False, False, False, False],\n",
              "  18: [True],\n",
              "  21: [False, True, False, False],\n",
              "  22: [True, False]},\n",
              " {1: ':',\n",
              "  2: 'Suggestion:',\n",
              "  3: 'Date:',\n",
              "  4: 'Licensee',\n",
              "  5: '',\n",
              "  6: 'Yes',\n",
              "  7: 'No',\n",
              "  10: 'Name / Phone Ext. :',\n",
              "  11: 'M. Hamann P. Harper, P. Martinez',\n",
              "  12: '9/ 3/ 92',\n",
              "  13: 'R&D Group:',\n",
              "  14: 'J. S. Wigand',\n",
              "  15: 'Supervisor / Manager',\n",
              "  16: 'Discontinue coal retention analyses on licensee submitted product samples (Note : Coal Retention testing is not performed by most licensees. Other B&W physical measurements as ends stability and inspection for soft spots in ciparettes are thought to be sufficient measures to assure cigarette physical integrity. The proposed action will increase laboratory productivity . )',\n",
              "  17: 'Suggested Solutions (s) :',\n",
              "  18: 'Delete coal retention from the list of standard analyses performed on licensee submitted product samples. Special requests for coal retention testing could still be submitted on an exception basis.',\n",
              "  20: 'Manager Comments:',\n",
              "  21: 'Manager, please contact suggester and forward',\n",
              "  22: 'comments to the Quality Council.'})"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7pQub9q-p-w4"
      },
      "source": [
        "### Dataset Class\n",
        "\n",
        "We create this class in order to obtain the dataset we will use for training the BERT model. \n",
        "For each form we extract all the answers and its candidates for question. For each candidate we concatenate its text with the answer text. If the link between those 2 entities exists the label will be: 1 and if it doesn't exist it will be 0."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eoHvWXOa9sOC"
      },
      "source": [
        "import os\n",
        "class Dataset():\n",
        "    def __init__(self, path_annotation):\n",
        "        self.path_annotation= path_annotation\n",
        "\n",
        "    def __iter__(self):\n",
        "      with os.scandir(self.path_annotation) as files:\n",
        "        for file in files:\n",
        "          yield file.name\n",
        "          \n",
        "    def __len__(self):\n",
        "      i=0\n",
        "      for file in self:\n",
        "        i+=1\n",
        "      return i\n",
        "\n",
        "    def textList(self, o):\n",
        "      path=self.path_annotation+'/'+o\n",
        "      cand,label,text=candidatesANDlabels(path)\n",
        "      question_answer,et=[],[]\n",
        "      dic={True:1,False:0}\n",
        "      for c in cand:\n",
        "        question_answer=question_answer+[text[x]+' '+text[c] for x in cand[c]]\n",
        "        et=et+[dic[z] for z in label[c]]\n",
        "      return question_answer,et\n",
        "    \n",
        "    def preparation(self):\n",
        "      text=[]\n",
        "      label=[]\n",
        "      for file in self:\n",
        "        txt,lbl=self.textList(file)\n",
        "        text=text+txt\n",
        "        label=label+lbl\n",
        "      return (text,label)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gZR_FPAk-Jv_"
      },
      "source": [
        "dataset_train=Dataset('dataset/training_data/annotations')\n",
        "dataset_test=Dataset('dataset/testing_data/annotations')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D411kM4R-JwA"
      },
      "source": [
        "text_train, labels_train=dataset_train.preparation()\n",
        "text_test, labels_test=dataset_test.preparation()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dauKcE4PyLvW"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "train_texts, val_texts, train_labels, val_labels = train_test_split(text_train, labels_train, test_size=.2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I5rUCbt9R90S"
      },
      "source": [
        "**We check if all the answers have at least one question in their candidates:**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6FZrZMpBPxfJ",
        "outputId": "b71a8e3e-f61c-4081-c388-56b3815f520f"
      },
      "source": [
        "path='/content/dataset/training_data/annotations/'\n",
        "i=0\n",
        "for f in dataset_train:\n",
        "  f=path+f\n",
        "  cand,_,_=candidatesANDlabels(f)\n",
        "  for c in cand:\n",
        "    if cand[c]==[]:\n",
        "      i+=1\n",
        "print(i)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9De31K65BFLt"
      },
      "source": [
        "There's no answer without candidates"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ApCMyoP2SQuC"
      },
      "source": [
        "**We check if all the correct questions are in the candidate list of the answer:**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qhMaLeVXN9Li",
        "outputId": "77dd1657-097a-4fd7-af6b-427fcfd417aa"
      },
      "source": [
        "path='/content/dataset/training_data/annotations/'\n",
        "i,j=0,0\n",
        "for f in dataset_train:\n",
        "  f=path+f\n",
        "  cand,lbl,text=candidatesANDlabels(f)\n",
        "  for k in lbl:\n",
        "    j+=1\n",
        "    if not(True in lbl[k]):\n",
        "      i+=1\n",
        "print(i,j)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "47 2802\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VTvP1DyGTlu-",
        "outputId": "95526101-a99d-4995-b028-b207c89cbda9"
      },
      "source": [
        "47*100/2802"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1.6773733047822983"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tWDWXVLZBPHq"
      },
      "source": [
        "Ther're 47 of the 2802 answers (1.68%) who haven't got their correct question in the candidates"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O0lkdWyJqCKm"
      },
      "source": [
        "### FUNSDataset Class\n",
        "\n",
        "This class helps us to pass the dataset in a format that the model understands."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5c_k-d9bCKDh"
      },
      "source": [
        "import torch\n",
        "class FUNDSDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, encodings, labels):\n",
        "        self.encodings = encodings\n",
        "        self.labels = torch.tensor(labels)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
        "        item['labels'] = torch.tensor(self.labels[idx])\n",
        "        return item\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.labels)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FRhb9ps7qNwI"
      },
      "source": [
        "## Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "28HYwtoMvRkJ"
      },
      "source": [
        "%%capture\n",
        "pip install transformers"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "32IDKwgZqLkI"
      },
      "source": [
        "#### Metrics\n",
        "\n",
        "These are the metrics we will be using for training."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x6HkktDs9R0g"
      },
      "source": [
        "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
        "\n",
        "def compute_metrics(pred):\n",
        "    labels = pred.label_ids\n",
        "    preds = pred.predictions.argmax(-1)\n",
        "    precision, recall, f1, _ = precision_recall_fscore_support(labels, preds, average='binary')\n",
        "    acc = accuracy_score(labels, preds)\n",
        "    return {\n",
        "        'accuracy': acc,\n",
        "        'f1': f1,\n",
        "        'precision': precision,\n",
        "        'recall': recall\n",
        "    }"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iqmmSgmYyLC3"
      },
      "source": [
        "##### mAP"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6RZbikyY5Z3g"
      },
      "source": [
        "import numpy as np\n",
        "from sklearn.metrics import average_precision_score\n",
        "\n",
        "def mAP_x(scores, labels):\n",
        "  m=average_precision_score(labels, scores)\n",
        "  if np.isnan(m):\n",
        "    return 0\n",
        "  else:\n",
        "    return m"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U4MJSWZKBWOt"
      },
      "source": [
        "def mAP(dataset,coef_FINAL,labels):\n",
        "  i=0\n",
        "  map=[]\n",
        "  for f in dataset:\n",
        "    cand,txt=rank(dataset.path_annotation+ '/' +f)\n",
        "    n=len(cand)\n",
        "    if n>0:\n",
        "      for c in cand:\n",
        "        j=i+len(cand[c])\n",
        "        map.append(mAP_x(coef_FINAL[i:j],labels[i:j]))\n",
        "        i=j\n",
        "  return sum(map)/len(map)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MgWj17MnAYx5"
      },
      "source": [
        "##### mRank"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zBz9VQNzOOgE"
      },
      "source": [
        "import numpy as np\n",
        "def mRank_x(predictions, labels,coef):\n",
        "  if predictions==labels:\n",
        "    return 0\n",
        "  else:\n",
        "    if 1 in labels:\n",
        "      k=labels.index(1)\n",
        "      return sum([c>coef[k] for c in coef])\n",
        "    else:\n",
        "      return len(predictions)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fXPgzQfJOOgF"
      },
      "source": [
        "def mRank(dataset,prediction,labels,coef):\n",
        "  mrank=[]\n",
        "  i=0\n",
        "  for f in dataset:\n",
        "    cand,txt=rank(dataset.path_annotation+ '/' +f)\n",
        "    n=len(cand)\n",
        "    if n>0: #comprobamos que el documento tenga algun par clave-valor\n",
        "      for c in cand:\n",
        "        j=i+len(cand[c])\n",
        "        if j!=i:\n",
        "          mrank.append(mRank_x(prediction[i:j],labels[i:j],coef[i:j]))\n",
        "          i=j\n",
        "  return sum(mrank)/len(mrank)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KELzPZz34PpO"
      },
      "source": [
        "#### Tokenizer and model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282,
          "referenced_widgets": [
            "3bf259d2f95e4c7f984dc17051e0e189",
            "1ff1687440f44a1ab6b46b4c8673409d",
            "da65182e3a8a40488bc0f2b8a6c0eb0b",
            "8ab88a48f36a4e9db021cd3161b1b51c",
            "ce5f1681833f46e3950b9c140f8edf6f"
          ]
        },
        "id": "MiLQH8EYrIDM",
        "outputId": "bc2da8bc-5bf2-46a0-a754-36839670bf53"
      },
      "source": [
        "from transformers import BertForSequenceClassification,BertTokenizer,Trainer, TrainingArguments\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
        "model = BertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "3bf259d2f95e4c7f984dc17051e0e189",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/226k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "1ff1687440f44a1ab6b46b4c8673409d",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/28.0 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "da65182e3a8a40488bc0f2b8a6c0eb0b",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/455k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "8ab88a48f36a4e9db021cd3161b1b51c",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/570 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "ce5f1681833f46e3950b9c140f8edf6f",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/420M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_BY-1Ubg8vzT"
      },
      "source": [
        "train_encodings = tokenizer(train_texts, truncation=True, padding=True)\n",
        "val_encodings = tokenizer(val_texts, truncation=True, padding=True)\n",
        "test_encodings = tokenizer(text_test, truncation=True, padding=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C9174BnI8vzU"
      },
      "source": [
        "train_dataset = FUNDSDataset(train_encodings, train_labels)\n",
        "val_dataset = FUNDSDataset(val_encodings, val_labels)\n",
        "test_dataset = FUNDSDataset(test_encodings, labels_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3_YfkHum4b3J"
      },
      "source": [
        "#### Training arguments:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oM9OAKa5pvVM"
      },
      "source": [
        "args = TrainingArguments(\n",
        "    output_dir='./results',\n",
        "    evaluation_strategy = \"epoch\",\n",
        "    save_strategy='epoch',\n",
        "    learning_rate=2e-5,\n",
        "    per_device_train_batch_size=32,\n",
        "    per_device_eval_batch_size=16,\n",
        "    num_train_epochs=6,\n",
        "    weight_decay=0.01,\n",
        "    load_best_model_at_end=True,\n",
        "    metric_for_best_model='f1',\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SfeAlTPlpvVM"
      },
      "source": [
        "trainer = Trainer(\n",
        "    model,\n",
        "    args,\n",
        "    train_dataset=train_dataset,\n",
        "    eval_dataset=val_dataset,\n",
        "    tokenizer=tokenizer,\n",
        "    compute_metrics=compute_metrics\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rS9w8dtB4fbM"
      },
      "source": [
        "#### Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "v-bhukt2pvVN",
        "outputId": "891f8ec8-3270-49bd-9ebf-d4c1f1c8edf1"
      },
      "source": [
        "trainer.train() "
      ],
      "execution_count": null,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "***** Running training *****\n",
            "  Num examples = 10502\n",
            "  Num Epochs = 6\n",
            "  Instantaneous batch size per device = 32\n",
            "  Total train batch size (w. parallel, distributed & accumulation) = 32\n",
            "  Gradient Accumulation steps = 1\n",
            "  Total optimization steps = 1974\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  if __name__ == '__main__':\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='1974' max='1974' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [1974/1974 48:23, Epoch 6/6]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>F1</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.481516</td>\n",
              "      <td>0.787129</td>\n",
              "      <td>0.394366</td>\n",
              "      <td>0.551515</td>\n",
              "      <td>0.306914</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.476800</td>\n",
              "      <td>0.458053</td>\n",
              "      <td>0.805407</td>\n",
              "      <td>0.416000</td>\n",
              "      <td>0.645390</td>\n",
              "      <td>0.306914</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.476800</td>\n",
              "      <td>0.475555</td>\n",
              "      <td>0.808835</td>\n",
              "      <td>0.472689</td>\n",
              "      <td>0.626741</td>\n",
              "      <td>0.379427</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.374800</td>\n",
              "      <td>0.517237</td>\n",
              "      <td>0.795126</td>\n",
              "      <td>0.516187</td>\n",
              "      <td>0.552987</td>\n",
              "      <td>0.483980</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.273900</td>\n",
              "      <td>0.557764</td>\n",
              "      <td>0.782940</td>\n",
              "      <td>0.515306</td>\n",
              "      <td>0.519726</td>\n",
              "      <td>0.510961</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>0.273900</td>\n",
              "      <td>0.594904</td>\n",
              "      <td>0.781036</td>\n",
              "      <td>0.508967</td>\n",
              "      <td>0.515571</td>\n",
              "      <td>0.502530</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "***** Running Evaluation *****\n",
            "  Num examples = 2626\n",
            "  Batch size = 16\n",
            "Saving model checkpoint to ./results/checkpoint-329\n",
            "Configuration saved in ./results/checkpoint-329/config.json\n",
            "Model weights saved in ./results/checkpoint-329/pytorch_model.bin\n",
            "tokenizer config file saved in ./results/checkpoint-329/tokenizer_config.json\n",
            "Special tokens file saved in ./results/checkpoint-329/special_tokens_map.json\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  if __name__ == '__main__':\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 2626\n",
            "  Batch size = 16\n",
            "Saving model checkpoint to ./results/checkpoint-658\n",
            "Configuration saved in ./results/checkpoint-658/config.json\n",
            "Model weights saved in ./results/checkpoint-658/pytorch_model.bin\n",
            "tokenizer config file saved in ./results/checkpoint-658/tokenizer_config.json\n",
            "Special tokens file saved in ./results/checkpoint-658/special_tokens_map.json\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  if __name__ == '__main__':\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 2626\n",
            "  Batch size = 16\n",
            "Saving model checkpoint to ./results/checkpoint-987\n",
            "Configuration saved in ./results/checkpoint-987/config.json\n",
            "Model weights saved in ./results/checkpoint-987/pytorch_model.bin\n",
            "tokenizer config file saved in ./results/checkpoint-987/tokenizer_config.json\n",
            "Special tokens file saved in ./results/checkpoint-987/special_tokens_map.json\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  if __name__ == '__main__':\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 2626\n",
            "  Batch size = 16\n",
            "Saving model checkpoint to ./results/checkpoint-1316\n",
            "Configuration saved in ./results/checkpoint-1316/config.json\n",
            "Model weights saved in ./results/checkpoint-1316/pytorch_model.bin\n",
            "tokenizer config file saved in ./results/checkpoint-1316/tokenizer_config.json\n",
            "Special tokens file saved in ./results/checkpoint-1316/special_tokens_map.json\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  if __name__ == '__main__':\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 2626\n",
            "  Batch size = 16\n",
            "Saving model checkpoint to ./results/checkpoint-1645\n",
            "Configuration saved in ./results/checkpoint-1645/config.json\n",
            "Model weights saved in ./results/checkpoint-1645/pytorch_model.bin\n",
            "tokenizer config file saved in ./results/checkpoint-1645/tokenizer_config.json\n",
            "Special tokens file saved in ./results/checkpoint-1645/special_tokens_map.json\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  if __name__ == '__main__':\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 2626\n",
            "  Batch size = 16\n",
            "Saving model checkpoint to ./results/checkpoint-1974\n",
            "Configuration saved in ./results/checkpoint-1974/config.json\n",
            "Model weights saved in ./results/checkpoint-1974/pytorch_model.bin\n",
            "tokenizer config file saved in ./results/checkpoint-1974/tokenizer_config.json\n",
            "Special tokens file saved in ./results/checkpoint-1974/special_tokens_map.json\n",
            "\n",
            "\n",
            "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
            "\n",
            "\n",
            "Loading best model from ./results/checkpoint-1316 (score: 0.5161870503597122).\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "TrainOutput(global_step=1974, training_loss=0.3405203737144895, metrics={'train_runtime': 2904.9247, 'train_samples_per_second': 21.691, 'train_steps_per_second': 0.68, 'total_flos': 4565743532555760.0, 'train_loss': 0.3405203737144895, 'epoch': 6.0})"
            ]
          },
          "execution_count": null,
          "metadata": {},
          "output_type": "execute_result"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rPY77QdItBYe"
      },
      "source": [
        "Saving the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L_GLv-kggRcX",
        "outputId": "dd080057-aeae-4d6a-d9f6-fe7c0be0195d"
      },
      "source": [
        "trainer.save_model('BERT')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Saving model checkpoint to BERT\n",
            "Configuration saved in BERT/config.json\n",
            "Model weights saved in BERT/pytorch_model.bin\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iBPzV3Ck8P7m",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "dfc7dc7a-1404-4e66-d231-923d664e1cdb"
      },
      "source": [
        "import shutil\n",
        "shutil.make_archive('BERT', 'zip', 'BERT')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'/content/BERT.zip'"
            ]
          },
          "metadata": {},
          "execution_count": 269
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9MMI8-44qnga"
      },
      "source": [
        "## Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        },
        "id": "8RM-BCErHyBL",
        "outputId": "2b0bb372-c07a-46d9-d488-900632951362"
      },
      "source": [
        "trainer.evaluate(test_dataset)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "***** Running Evaluation *****\n",
            "  Num examples = 4002\n",
            "  Batch size = 8\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  if __name__ == '__main__':\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='501' max='501' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [501/501 01:30]\n",
              "    </div>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'eval_accuracy': 0.8018490754622689,\n",
              " 'eval_f1': 0.5770666666666666,\n",
              " 'eval_loss': 0.49730122089385986,\n",
              " 'eval_precision': 0.517208413001912,\n",
              " 'eval_recall': 0.6525934861278649,\n",
              " 'eval_runtime': 90.5719,\n",
              " 'eval_samples_per_second': 44.186,\n",
              " 'eval_steps_per_second': 5.532}"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RYwA_OjN4tcW"
      },
      "source": [
        "## Downloading and loading the trained weights"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NccSt3mrIMlY",
        "outputId": "ad2c6b24-d0d6-45b3-abd6-3c1ee93a0a3f"
      },
      "source": [
        "import shutil\n",
        "!wget https://github.com/mavillot/FUNSD-Entity-Linking/releases/download/BERT/BERT.zip\n",
        "shutil.unpack_archive('BERT.zip', 'BERT')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2021-10-18 07:11:12--  https://github.com/mavillot/FUNSD-Entity-Linking/releases/download/BERT/BERT.zip\n",
            "Resolving github.com (github.com)... 140.82.121.3\n",
            "Connecting to github.com (github.com)|140.82.121.3|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://github-releases.githubusercontent.com/417075062/ed4518cf-428a-4f5f-b1dc-6bbebded41af?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20211018%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20211018T071112Z&X-Amz-Expires=300&X-Amz-Signature=893032fbe2c0427d71fc90d1d6e23170ff3b20fbde6117bb09192ea6f364fd20&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=417075062&response-content-disposition=attachment%3B%20filename%3DBERT.zip&response-content-type=application%2Foctet-stream [following]\n",
            "--2021-10-18 07:11:12--  https://github-releases.githubusercontent.com/417075062/ed4518cf-428a-4f5f-b1dc-6bbebded41af?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20211018%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20211018T071112Z&X-Amz-Expires=300&X-Amz-Signature=893032fbe2c0427d71fc90d1d6e23170ff3b20fbde6117bb09192ea6f364fd20&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=417075062&response-content-disposition=attachment%3B%20filename%3DBERT.zip&response-content-type=application%2Foctet-stream\n",
            "Resolving github-releases.githubusercontent.com (github-releases.githubusercontent.com)... 185.199.111.154, 185.199.110.154, 185.199.108.154, ...\n",
            "Connecting to github-releases.githubusercontent.com (github-releases.githubusercontent.com)|185.199.111.154|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 405714685 (387M) [application/octet-stream]\n",
            "Saving to: ‘BERT.zip’\n",
            "\n",
            "BERT.zip            100%[===================>] 386.92M  48.6MB/s    in 8.4s    \n",
            "\n",
            "2021-10-18 07:11:21 (45.8 MB/s) - ‘BERT.zip’ saved [405714685/405714685]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PgCTy7KXiBUp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ce60966c-989a-43af-a72f-fc4ee73f726e"
      },
      "source": [
        "from transformers import BertForSequenceClassification,BertTokenizer,Trainer\n",
        "tokenizer = BertTokenizer.from_pretrained('BERT')\n",
        "model = BertForSequenceClassification.from_pretrained('BERT', num_labels=2)\n",
        "trainer = Trainer(model,compute_metrics=compute_metrics)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Didn't find file BERT/added_tokens.json. We won't load it.\n",
            "Didn't find file BERT/tokenizer.json. We won't load it.\n",
            "loading file BERT/vocab.txt\n",
            "loading file None\n",
            "loading file BERT/special_tokens_map.json\n",
            "loading file BERT/tokenizer_config.json\n",
            "loading file None\n",
            "loading configuration file BERT/config.json\n",
            "Model config BertConfig {\n",
            "  \"_name_or_path\": \"model\",\n",
            "  \"architectures\": [\n",
            "    \"BertForSequenceClassification\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"classifier_dropout\": null,\n",
            "  \"gradient_checkpointing\": false,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"bert\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"position_embedding_type\": \"absolute\",\n",
            "  \"problem_type\": \"single_label_classification\",\n",
            "  \"torch_dtype\": \"float32\",\n",
            "  \"transformers_version\": \"4.11.3\",\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 30522\n",
            "}\n",
            "\n",
            "loading weights file BERT/pytorch_model.bin\n",
            "All model checkpoint weights were used when initializing BertForSequenceClassification.\n",
            "\n",
            "All the weights of BertForSequenceClassification were initialized from the model checkpoint at BERT.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use BertForSequenceClassification for predictions without further training.\n",
            "No `TrainingArguments` passed, using `output_dir=tmp_trainer`.\n",
            "PyTorch: setting up devices\n",
            "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9aY5hDwcwKLr"
      },
      "source": [
        "## Ideas\n",
        "In order to improve the results (f1=0.58) we will use the rules based on the following points:\n",
        "- An answer is only linked to one **unique** question. Therefore, if the model has predicted that there is more than one correct question, we will take the first one (it is the one with the smallest distance).\n",
        "- It is mandatory for an answer to have **one** question. Therefore, if the model hasn't predicted any of the candidates as the correct question, we transform the first question as correct.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BiAMSOUVxDSS"
      },
      "source": [
        "### Example:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0HX4jI18pvVQ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 142
        },
        "outputId": "9904ee8c-44be-4cc8-9381-178f5444a706"
      },
      "source": [
        "ejemplo=Dataset('dataset/testing_data/annotations')\n",
        "cand,txt=rank('dataset/testing_data/annotations/82252956_2958.json')\n",
        "text_ej, labels_ej=ejemplo.textList('82252956_2958.json')\n",
        "encodings = tokenizer(text_ej, truncation=True, padding=True)\n",
        "dataEJ = FUNDSDataset(encodings, labels_ej)\n",
        "coef=trainer.predict(dataEJ)[0]\n",
        "prediction=coef.argmax(-1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "***** Running Prediction *****\n",
            "  Num examples = 38\n",
            "  Batch size = 8\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  if __name__ == '__main__':\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='10' max='5' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [5/5 13:57]\n",
              "    </div>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xkWlrFU4XfJK"
      },
      "source": [
        "path=ejemplo.path_annotation\n",
        "def rules(cand, pred,coef):\n",
        "  i=0\n",
        "  pred_FINAL,coef_FINAL=[],[]\n",
        "  for c in cand:\n",
        "    j=i+len(cand[c])\n",
        "    new_pred=pred[i:j]\n",
        "    new_coef=coef[i:j]\n",
        "    if new_pred!=[]:\n",
        "      if 1 in new_pred:\n",
        "        encontrado=False\n",
        "        m=0\n",
        "        while encontrado==False:\n",
        "          if new_pred[m]==1:\n",
        "            encontrado=True\n",
        "            new_coef[m]=10\n",
        "          m+=1\n",
        "        for k in range(m,j-i):\n",
        "          new_pred[k]=0\n",
        "      else:\n",
        "        new_pred[0]=1\n",
        "        new_coef[0]=10\n",
        "      i=j\n",
        "      pred_FINAL=pred_FINAL+new_pred\n",
        "      coef_FINAL=coef_FINAL+new_coef\n",
        "  return pred_FINAL,coef_FINAL"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GjJG6YjY3v4C",
        "outputId": "86575d89-3408-470a-e3db-3cc622e057cf"
      },
      "source": [
        "cand"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{6: [30, 21, 27, 22, 4],\n",
              " 7: [31, 30, 21, 28, 27, 23, 22],\n",
              " 15: [34, 35],\n",
              " 16: [36, 35, 37, 34],\n",
              " 17: [8],\n",
              " 19: [9, 8],\n",
              " 20: [10, 9, 8, 2, 3, 0, 1],\n",
              " 25: [22, 4, 27, 21],\n",
              " 26: [23, 22, 28, 27, 21],\n",
              " 41: [34]}"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gZRgxmMiswLS",
        "outputId": "c1c49ca9-ae12-4c57-97ef-aa5da243c33d"
      },
      "source": [
        "print(labels_ej)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nPwOrn3hsxrZ",
        "outputId": "d23a6e38-746d-4861-b3fa-2524003ae6c5"
      },
      "source": [
        "print(prediction)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1 0 0 0 0 1 1 0 0 0 0 0 0 1 1 0 0 0 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 1]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hxqUhBLgaLt_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7ea9b6ef-4bcb-416c-bf16-c9ecd8f58ac2"
      },
      "source": [
        "prediction_FINAL, coef_FINAL=rules(cand,prediction,coef)\n",
        "print(prediction_FINAL)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UY0IoI3DvYB6",
        "outputId": "d7892d18-a2fe-4799-f189-988fade8314e"
      },
      "source": [
        "precision, recall, f1, _ = precision_recall_fscore_support(labels_ej, prediction, average='binary')\n",
        "acc = accuracy_score(labels_ej, prediction)\n",
        "\n",
        "print('accuracy: ',acc)\n",
        "print('precision: ',precision)\n",
        "print('recall: ',recall)\n",
        "print('f1: ',f1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "accuracy:  0.8947368421052632\n",
            "precision:  0.8\n",
            "recall:  0.8\n",
            "f1:  0.8000000000000002\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uA1--uqDvD7H",
        "outputId": "3196bd52-f46c-4840-991c-7cee0a1901c4"
      },
      "source": [
        "precision, recall, f1, _ = precision_recall_fscore_support(labels_ej, prediction_FINAL, average='binary')\n",
        "acc = accuracy_score(labels_ej, prediction_FINAL)\n",
        "\n",
        "print('accuracy: ',acc)\n",
        "print('precision: ',precision)\n",
        "print('recall: ',recall)\n",
        "print('f1: ',f1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "accuracy:  1.0\n",
            "precision:  1.0\n",
            "recall:  1.0\n",
            "f1:  1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SHg-GixbxHOx"
      },
      "source": [
        "It seems like it works fine"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FqnJOgkX2nnc"
      },
      "source": [
        "# Results"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cDlApZq8uwij"
      },
      "source": [
        "We build our test dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4km8oIFjuhAA"
      },
      "source": [
        "dataset_test=Dataset('dataset/testing_data/annotations')\n",
        "text_test, labels_test=dataset_test.preparation()\n",
        "test_encodings = tokenizer(text_test, truncation=True, padding=True)\n",
        "test_dataset = FUNDSDataset(test_encodings, labels_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mTO31eesiFVN"
      },
      "source": [
        "**We check if all the answers have at least one question in their candidates:**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5iufGy2jiKE9",
        "outputId": "3307a099-64b9-4340-8c03-adff6c8a73cf"
      },
      "source": [
        "path='/content/dataset/testing_data/annotations/'\n",
        "i=0\n",
        "for f in dataset_test:\n",
        "  f=path+f\n",
        "  cand,_,_=candidatesANDlabels(f)\n",
        "  for c in cand:\n",
        "    if cand[c]==[]:\n",
        "      i+=1\n",
        "print(i)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e0b3G_kjiSds"
      },
      "source": [
        "There's no answer without candidates"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5ZIkTrnCiFVN"
      },
      "source": [
        "**We check if all the correct questions are in the candidate list of the answer:**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GJVKorY2iZR9",
        "outputId": "74699186-b9c6-4f45-83f7-1563c57196c4"
      },
      "source": [
        "path='/content/dataset/testing_data/annotations/'\n",
        "i,j=0,0\n",
        "for f in dataset_test:\n",
        "  f=path+f\n",
        "  _,lbl,_=candidatesANDlabels(f)\n",
        "  for k in lbl:\n",
        "    j+=1\n",
        "    if not(True in lbl[k]):\n",
        "      i+=1\n",
        "print(i,j)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3 821\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kWO4pX3-iZR-",
        "outputId": "95f2df09-52b7-4d7a-8a4c-0cde121ca3fe"
      },
      "source": [
        "3*100/821"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.3654080389768575"
            ]
          },
          "metadata": {},
          "execution_count": 103
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H0HHQTISiFVO"
      },
      "source": [
        "Ther're 3 of the 821 answers (0.37%) who haven't got their correct question in the candidates"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "94lXrlBaksoA"
      },
      "source": [
        "### PREDICTIONS"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VpYIaKpnQv9O"
      },
      "source": [
        "coef=trainer.predict(test_dataset)[0]\n",
        "prediction=coef.argmax(-1)\n",
        "prediction=[p for p in prediction]\n",
        "coef=[tupla[1] for tupla in coef]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fi-UJlq-ExUH"
      },
      "source": [
        "### Results (Before the rules are applied)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kyy_aMYwzckn",
        "outputId": "ff834986-e533-4d1c-cf96-7d594bbc160a"
      },
      "source": [
        "precision, recall, f1, _ = precision_recall_fscore_support(labels_test, prediction, average='binary')\n",
        "acc = accuracy_score(labels_test, prediction)\n",
        "print('accuracy: ',acc)\n",
        "print('precision: ',precision)\n",
        "print('recall: ',recall)\n",
        "print('f1: ',f1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "accuracy:  0.8018490754622689\n",
            "precision:  0.517208413001912\n",
            "recall:  0.6525934861278649\n",
            "f1:  0.5770666666666666\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z_Z1FpCNkAGu",
        "outputId": "83aef61e-90e4-4331-a7df-3e7697dfd861"
      },
      "source": [
        "mAP(dataset_test,coef,labels_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_ranking.py:677: RuntimeWarning: invalid value encountered in true_divide\n",
            "  recall = tps / tps[-1]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.7736070162075037"
            ]
          },
          "metadata": {},
          "execution_count": 114
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h1hXa4EbkAG5",
        "outputId": "ad369f12-914a-48e0-ce64-2aedc882e720"
      },
      "source": [
        "mRank(dataset_test,prediction,labels_test,coef)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.6516443361753959"
            ]
          },
          "metadata": {},
          "execution_count": 115
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kcDnmj5Vkkys"
      },
      "source": [
        "### Results (After the rules are applied)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gXWsD7w9h5XB"
      },
      "source": [
        "RULES:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u62UW6MpbwqC"
      },
      "source": [
        "path=dataset_test.path_annotation+'/'\n",
        "a=0\n",
        "prediction_FINAL,coef_FINAL=[],[]\n",
        "for f in dataset_test:\n",
        "  cand,txt=rank(path+f)\n",
        "  lenght=0\n",
        "  for c in cand:\n",
        "    lenght+=len(cand[c])\n",
        "  b=a+lenght\n",
        "  pred,cf=rules(cand, prediction[a:b],coef[a:b])\n",
        "  prediction_FINAL=prediction_FINAL+pred\n",
        "  coef_FINAL=coef_FINAL+cf\n",
        "  a=b"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XDrpP2l08PBM",
        "outputId": "d51b182b-5aab-407a-e945-8bed2a8933df"
      },
      "source": [
        "precision, recall, f1, _ = precision_recall_fscore_support(labels_test, prediction_FINAL, average='binary')\n",
        "acc = accuracy_score(labels_test, prediction_FINAL)\n",
        "print('accuracy: ',acc)\n",
        "print('precision: ',precision)\n",
        "print('recall: ',recall)\n",
        "print('f1: ',f1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "accuracy:  0.9170414792603698\n",
            "precision:  0.8026796589524969\n",
            "recall:  0.7949336550060314\n",
            "f1:  0.7987878787878787\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WB4NWugU6m1D",
        "outputId": "8669b4b8-a727-4a33-ebc3-1488a1f31b36"
      },
      "source": [
        "mAP(dataset_test,coef_FINAL,labels_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_ranking.py:677: RuntimeWarning: invalid value encountered in true_divide\n",
            "  recall = tps / tps[-1]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8724088369338063"
            ]
          },
          "metadata": {},
          "execution_count": 121
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g-oA4RxpRxW4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "438d1c7d-2e04-47ee-8a4f-fc25d7959928"
      },
      "source": [
        "mRank(dataset_test,prediction_FINAL,labels_test,coef_FINAL)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.4933008526187576"
            ]
          },
          "metadata": {},
          "execution_count": 122
        }
      ]
    }
  ]
}